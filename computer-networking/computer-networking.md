## 计算机网络-自顶向下方法

### 1 计算机网络和因特网

#### 1.1 因特网

​		与因特网连接的设备称为**主机**^【因为容纳/运行应用程序】^或**端系统**^【因为位于因特网的边缘】^。

​		主机分为**客户端**和**服务器**。

​		端系统彼此交换**报文**。端系统通过**通信链路**和**分组交换机**连接到一起。

​		通信链路的**传输速度**的单位是bit/s。一台端系统向另一台端系统发送报文时，发送端将报文分段并为每段加上首部字节，由此形成的信息包称为**分组**。

​		交换机主要包括**路由器**和**链路层交换机**。链路层交换机通常用于接入网中，而路由器通常用于网络核心中。从发送端系统到接收端系统，一个分组所经历的一系列通信链路和分组交换机称为通过该网络的**路径**。

​		端系统通过**因特网服务提供商**接入因特网。

​		端系统、分组交换机和其他因特网部件都要运行一系列**协议**，这些协议控制因特网中信息的接收和发送。**IP**协议定义了在路由器和端系统之间发送和接收的分组格式。因特网的主要协议统称为**TCP/IP**。

​		**协议**定义了两个或多个通信实体之间交换的报文的格式和顺序，以及发送/接收一条报文或其他事件所采取的动作。

​		**因特网标准**由**因特网工程任务组**研发，其标准文档称为**请求评论**。

​		应用程序涉及多个相互交换数据的端系统称为**分布式应用程序**。

​		与因特网相连的端系统提供了一个**套接字接口**，该接口规定了运行在端系统上的程序请求因特网基础设施向运行在另一个端系统上的特定目的地程序交付数据的方式。

​		ICANN负责分配IP地址，分配AS号，管理DNS根服务器，分配域名以及解决域名纷争。

#### 1.2 网络边缘

​		**接入网**指将端系统物理连接到其边缘路由器的网络。**边缘路由器**是端系统到任何其他远程端系统的路径上的第一台路由器。

​		家庭接入：DSL、电缆、FTTH、拨号和卫星

​		企业/家庭接入：以太网和WiFi

​		广域无线接入：3G/4G/5G和LTE

​		**物理媒体**包括**导引型媒体**^【电波沿着固态媒体传播】^和**非导引型媒体**^【电波在空气或外层空间传播】^。

#### 1.3 网络核心

​		通过网络链路和交换机移动数据有两种基本方法：**分组交换**和**电路交换**。

​		在电路交换的网络中，端系统间通信会话期间，==预留==了端系统间沿路径通信所需要的资源^【缓存和链路传输速度】^，而在分组交换的网络中==不会预留==这些资源。

##### 1.3.1 分组交换

​		多数分组交换机在链路的输入的使用**存储转发传输**机制。存储转发传输是指在交换机能够开始向输出链路传输该分组的第一个比特之前，必须接收到整个分组。

![store-and-forward_packet_switching](img/store-and-forward_packet_switching.png)

​		通过有`N`条速度均为`R`的链路组成的路径，其中有`N-1`台路由器，则端到端时延：$d_{端到端}=N\frac{L}{R}$。

​		对于每条相连的链路，分组交换机有一个用来存储路由器准备发往该链路的分组的**输出缓存/队列**。

![packet_switching](img/packet_switching.png)

​		分组需要承受输出缓存的**排队时延**。

​		由于缓存空间是有限的，一个到达的分组可能发现该缓存已被其他待传输的分组完全占满，此时刚到达的分组或已经排队的分组其中之一将被丢弃，称为**分组丢失/丢包**。

​		每个端系统都有IP地址，分组的首部中包含了目的地的IP地址。

​		每台路由器具有一个将目的IP地址(一部分)映射成输出链路的**转发表**。

##### 1.3.2 电路交换

​		链路中的电路是通过**频分复用**或**时分复用**来实现的。

​		对于频分复用，链路的频谱由跨越链路创建的所有连接共享。在连接期间链路为每条连接专用一个频段，该频段的宽度称为**带宽**。

​		对于时分复用，时间被划分为固定期间的帧，并且每个帧又被划分为固定数量的时隙。当网络跨越一条链路创建一条连接时，网络在每个帧中为该连接指定一个时隙。

![fdm_and_tdm](img/fdm_and_tdm.png)

##### 1.3.3 网络的网络

​		因为接入ISP向全球传输ISP付费，故接入ISP被认为是**客户**，而全球传输ISP被认为是**提供商**。

​		在任何给定的区域，可能有一个**区域ISP**，每个区域ISP则与**第一层ISP连接**。

​		任何ISP(除了第一层ISP)可以选择**多宿**。

​		位于相同等级结构层次的邻近一对ISP能够**对等**。

​		**因特网交换点**是一个汇合点，多个ISP能够在这里一起对等。

![interconnection_of_isps](img/interconnection_of_isps.png)

#### 1.4 分组交换网

​		当分组从一个节点/主机/路由器沿着这条路劲到后继节点/主机/路由器，该节点在沿途的每个节点经受了几种不同类型的时延，其中最重要的是**节点处理时延**、**排队时延**、**传输时延**和**传播时延**，这些时延的总和是**节点总时延**。若用$d_{proc}$、$d_{queue}$、$d_{trans}$、$d_{prop}$、$d_{nodal}$分别表示处理时延、排队时延、传输时延、传播时延和节点总时延，则$d_{nodal}=d_{proc}+d_{queue}+d_{trans}+d_{prop}$。

![total_nodal_delay_of_router](img/total_nodal_delay_of_router.png)

​		检查分组首部和决定将该分组导向何处所需要的时间是**处理时延**的一部分。

​		在队列中，当分组在链路上等待传输时，需要经受**排队时延**。

​		**传输时延**是路由器推出分组所需的时间，可表示为$\frac{L}{R}$，$L$表示分组的长度，$R(b/s)$表示链路的传输速度，即从队列中推出1bit的速度。		

​		$\frac{L\alpha}{R}$是**流量强度**，其中$\alpha(pkt/s)$表示分组到达队列的平均速度。流量强度主要用于衡量排队时延，==设计系统时流量强度不能大于1==。

​		1bit从一个路由器到另一个路由器所需的时间是**传播时延**。

​		源主机和目的主机之间有$N-1$台路由器，网络通畅^【排队时延可以忽略】^，节点时延累加起来，得到端到端时延：
$$
\begin{align}
d_{end-end}&=N(d_{proc}+d_{trans}+d_{prop})\\&=N(d_{proc}+\frac{L}{R}+d_{prop})
\end{align}
$$

​		**吞吐量**是进程交互比特的速度。

#### 1.5 协议层次及其服务模型

​		某层的**服务模型**是该层向上一层提供的服务。

​		各层的所有协议被称为**协议栈**。

​		

![internet_protocol_stack_and_osi_reference_model](img/internet_protocol_stack_and_osi_reference_model.png)

##### 1.5.1 因特网协议栈

|        | 功能                                           | 主要协议                                  | 分组名称 |
| ------ | ---------------------------------------------- | ----------------------------------------- | -------- |
| 应用层 | 存留网络应用程序及它们的应用层协议             | HTTP、SMTP、FTP、DNS、DHCP、SNMP和NFS等   | 报文     |
| 传输层 | 应用程序端点之间传输应用层报文                 | TCP、UDP、DCCP、DCTCP、TRFC、SCTP和QUIC等 | 报文段   |
| 网络层 | 也称为IP层，将数据报从一台主机移动到另一台主机 | IP                                        | 数据报   |
| 链路层 | 沿着路劲将数据包传递给下一个节点               | 以太网、WiFi和DOCSIS                      | 帧       |
| 物理层 | 将帧中的一个个比特从一个节点移动到下一个节点   |                                           | 比特     |

|      应用      | 应用层协议 |          传输层协议和端口           |
| :------------: | :--------: | :---------------------------------: |
|    电子邮件    |    SMTP    |         TCP:25/465/587/2525         |
|  远程终端访问  |   Telnet   |               TCP:23                |
|      Web       |    HTTP    |               TCP:80                |
|    文件传输    |    FTP     |              TCP:20/21              |
| 远程文件服务器 |    NFS     |              UDP:2049               |
|   流式多媒体   |  通常专用  |               TCP/UDP               |
|   因特网电话   |  通常专用  |               TCP/UDP               |
|    网络管理    |    SNMP    |             UDP:161/162             |
|    域名系统    |    DNS     |               UDP:53                |
|    SSH隧道     |    SSH     |               TCP:22                |
|      DHCP      |   BOOTP    |      UDP:67(server)/68(client)      |
|      BGP       |    BGP     |               TCP:179               |
|    OpenFlow    |  OpenFlow  |              TCP:6653               |
|    网络管理    |    SNMP    | UDP:161/162/163或(D)TLS:10161/10162 |

##### 1.5.2 OSI模型

​		**网络体系结构**是通信系统的整体设计，其广泛采用OSI模型。

​		相比因特网协议栈，OSI模型多出表示层和会话层。

​		表示层的作用是使通信的应用程序能够解释交换数据的含义。这些服务包括数据压缩、数据加密和数据描述。

​		会话层提供了数据交换的定界和同步功能，包括了建立检查点和恢复方案的方法。

##### 1.5.3 封装

![encapsulation](img/encapsulation.png)

​		在每一层，分组包括首部字段和**有效载荷字段**^【通常是上一层的分组】^。

#### 1.6 网络安全

​		**病毒**是一种需要某种形式的用户交互来感染用户设备的恶意软件。

​		**蠕虫**是一种无须任何明显用户交互就能进入设备的恶意软件。

​		**Dos攻击**包括==弱点攻击==^【发送特殊的报文来控制或宕机】^、==带宽洪泛==^【发送大量分组】^和==连接洪泛==^【创建大量TCP连接】^。

​		用来观察执行协议实体之间交换的报文的基本工具被称为**分组嗅探器**。

​		**IP哄骗**指将具有虚假源地址的分组注入因特网。

### 第二章 应用层

#### 2.1 应用层协议原理

​		**套接字**是应用程序进程和传输层协议之间的接口。一个进程可以有多个套接字。

​		应用程序开发者可以通过套接字控制应用层的一切，但是对传输层的控制仅限于选择协议和设定几个传输层参数。应用程序体系结构通常使用客户端/服务器体系结构和对等体系结构。

​		当进程向另一台主机的进程发送分组时需要定义目的主机的地址和目的主机中接收进程的标识符。		

​		传输层为应用层提供的服务可分为四类：==可靠数据传输==、==吞吐量==、==定时==和==安全性==。

​		**带宽敏感的应用**具有吞吐量要求，而**弹性应用**能够根据可用的带宽。

​		**应用层协议**定义了运行在不同端系统上的应用程序进程如何相互传递报文：	

​		﹡交互的报文类型

​		﹡各种报文类型的语法

​		﹡字段的语义

​		﹡确定一个进程何时以及如何发送报文，对报文进行响应的规则

#### 2.2 HTTP

​		Web的应用层协议是**HTTP**。

​		HTTP服务器不保存关于客户端的任何信息，故HTTP是一个**无状态协议**。为了识别客户端，HTTP使用了cookie。

​		**持续连接**指一个TCP可以传输多个HTTP请求和响应。

​		**非持续连接**指一个TCP只能传输一个HTTP请求/响应对。

​		**Web缓存器**，也称为**代理服务器**，能够代表Web服务器来满足HTTP请求的网络实体。

​		HTTP的**条件GET**机制可以解决Web缓存器缓存的数据陈旧的问题。

​		HTTP主要是一个**拉协议**，TCP连接是由接收端发起。

##### 2.2.1 HTTP请求报文

```http
GET /somedir/page.html HTTP/2
Host: www.test.com
User-Agent: Mozilla/5.0
Accept: */*
Accept-Language: zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2
Accept-Encoding: gzip, deflate, br
Connection: keep-alive
```

​		HTTP请求报文的第一行是**请求行**。请求行包括方法字段、URL字段和HTTP版本字段。

​		HTTP请求报文第一行之后的行是**首部行**。

![http_request_message_format](img/http_request_message_format.png)

##### 2.2.2 HTTP响应报文

```http
HTTP/2 200 OK
content-type: text/javascript; charset=utf-8
content-encoding: br
last-modified: Wed, 03 Nov 2021 01:12:45 GMT
server: Windows-Azure-Blob/1.0 Microsoft-HTTPAPI/2.0
```

​		HTTP响应报文的第一行是**状态行**。请求行包括协议版本字段、状态码字段和相应状态字段。

​		HTTP响应报文第一行之后的行是**首部行**。

![http_response_message_format](img/http_response_message_format.png)

##### 2.2.3 条件GET

​		如果请求报文是GET方法且请求报文的首部行包括`If-modified-since`，该请求报文就是条件GET请求报文。

![conditional_get](img/conditional_get.png)

​		第三步中`If-modified-Since`的值等于第二步中`last-modified`的值，这表示Web服务器仅当指定日期之后该对象修改后才发送该对象，假设该对象在指定日期后没被修改，于是第四步中Web服务器向Web缓存器发送的响应报文中状态码为304且没有对象，表示Web缓存器可以转发缓存的该对象的副本。

#### 2.3 电子邮件

​		因特网电子邮件系统由**用户代理**、**邮件服务器**和**简单邮件传输协议**组成。

![e-mail_protocols_and_their_communicating_entities](img/e-mail_protocols_and_their_communicating_entities.png)

​		1）发件方调用用户代理撰写内容并发送邮件。

​		2）发件方的用户代理把报文发给发件方的邮件服务器，在这里报文被放在报文队列里。

​		3）发件方邮件服务器上的SMTP客户端创建一个到收件方邮件服务器上的SMTP服务器的TCP连接。

​		4）经过初始SMTP握手后，SMTP客户端通过TCP连接发送报文。

​		5）收件方邮件服务器的SMTP服务器接收到报文并将报文投入到收件方的邮箱。

​		6）收件方调用用户代理查看邮件。

##### 2.3.1 SMTP

​		SMTP是因特网电子邮件中主要的应用层协议。它限制了邮件的报文(不只是首部)只能采用7-bit ASCII表示，若报文包含非7-bit ASCII字符或二进制数据，需要进行7-bit ASCII编码。

​		SMTP是**推协议**，TCP连接是发送端发起的。

```ini
S: 220 client
C: EHLO server
S: 250 from | 250 PIPELINING | 250 SIZE 12345
C: AUTH XOAUTH2 oauth
S: 235 2.7.0 Accepted
C: MAIL FROM: <client@email.com> 
S: 250 OK
C: RCPT TO: <server@email.com>
S: 250 OK
C: DATA
S: 354 End data with <CR><LF>.<CR><LF>
C: DATA fragment,content
S: 250 OK: queued as.
C: QUIT
S: 221 Bye
```

​		SMTP协议中客户端发送了5条命令：HELO/EHLO^【ESMTP版本】^(HELLO缩写)、MAIL FROM、RCPT TO、DATA以及QUIT。

​		ESMTP相比SMTP，在发送邮件时==需要验证用户账户==。

##### 2.3.2 电子邮件

```ini
From: from@email.com
To: to@email.com
Subject: subject
```

​		邮件报文的首部行包括环境信息，必须包含一个`From`和一个`To`，可能包含`Subject`以及其他可选首部行。

​		在用户代理建立一个到邮件服务器110端口上的TCP连接后，POP3按照3个阶段进行工作：授权、事务处理以及更新。

​		﹡授权阶段需要用户代理以明文形式发送用户名和密码来认证，主要指令有`user <username>`和`pass <password>`。

​		﹡事务处理阶段中用户代理可以取回报文，也可以添加/取消报文删除标记，主要指令有`list`、`retr`和`dele`。

​		﹡更新阶段在用户代理发出`quit`指令并结束会话后，邮件服务器会删除那些被标记的报文。

​		POP3会话期间，邮件服务器会保留一些状态信息，但是在会话中不会携带这些信息。

​		IMAP使用了TCP连接的143端口。相比POP3，IMAP把报文和文件夹联系起来并且提供了创建/修改/删除文件夹和获取报文某些部分的指令。

#### 2.4 DNS

​		主机可以用**主机名**和**IP地址**来进行识别。

​		一台名为a.com的主机，可能还有别名b.com和c.com，此时a.com是**规范主机名**。

​		**域名系统**是一个由分层的**DNS服务器**实现的分布式数据库，一个让主机查询分布式数据库的应用层协议。主要用于将主机名解析为IP地址，也提供**主机别名**、**邮件服务器别名**和**负载分配**服务。

##### 2.4.1 DNS工作原理

​		DNS服务器主要分为**根DNS服务器**、**顶级域DNS服务器**、**权威DNS服务器**和**本地DNS服务器**。

​		﹡根DNS服务器提供顶级域DNS服务器的IP地址。

​		﹡每个顶级域^【如com、org、net、edu和gov等】^和国家的顶级域^【如uk、fr、ca和cn等】^都有顶级域DNS服务器(集群)。顶级域DNS服务器提供权威DNS服务器的IP地址。 

​		﹡因特网上具有公共可访问主机的每个组织机构必须提供公共可访问的DNS记录，这些记录将这些主机的名称映射为IP地址。

​		﹡每个ISP都有一个本地DNS服务器/默认名称服务器

![interaction_of_the_various_dns_servsers](img/interaction_of_the_various_dns_servsers.png)

​		一般情况下，从请求主机到本地DNS服务器的查询是**递归查询**，其余的查询是**迭代查询**。

​		为了降低时延并减少报文数量，**DNS缓存**广泛使用，因此在大部分DNS查询中根DNS服务器都被绕过。

##### 2.4.2 DNS报文

​		**资源记录**提供了主机名到IP地址的映射，格式为`(Name, Value, Type, TTL)`。

​		﹡`Type = A`时，`Name`是主机名，`Value`是主机名对应的IP地址。

​		﹡`Type = NS `时，`Name`是域名，`Value`是能够获取该域名中主机IP地址的权威DNS服务器的主机名。

​		﹡`Type = CNAME `时，`Value`是别名为`Name`的主机的规范主机名。

​		﹡`Type = MX`时，`Value`是别名为`Name`的邮件服务器的规范主机名。

​		对于某个主机名，若DNS服务器是它的权威DNS服务器，则该DNS服务器会有一条包含该主机名的A型记录。若DNS服务器不是它的权威服务器，则该DNS服务器会有一条该主机名所属域名的NS型记录，还会有一条包含该NS型记录中`Value`的A型记录，还可能会有一条包含该主机名的A型记录。

![dns_message_format](img/dns_message_format.png)

​		DNS报文分为查询和应答报文，报文格式相同。

​		﹡在首部区域，第一个字段占16位，用于标识该查询，该字段会被复制到应答报文中来匹配请求。第二个字段有若干1 位的标志位。0/1标识查询/应答报文。若请求的是权威DNS服务器则应答报文会设置[权威]标志位。若客户端在DNS服务器没有资源记录时希望它执行递归查询则会设置[希望递归]标志位。若DNS服务器支持递归查询则会在应答报文设置[递归可用]标志位。剩下四个字段表示后四个区域数据的数量。

​		﹡问题区域包名称字段和类型字段，名称字段是待查询的主机名称，类型字段对应资源记录中的类型字段。

​		﹡应答区域可以包含多条资源记录。		

​		﹡权威区域包含其他权威DNS服务器的资源记录。

​		﹡附加信息区域包含其他有用的资源记录。

#### 2.5 P2P文件分发

##### 2.5.1 P2P体系结构

​		**分发时间**是所有$n$个对等方得到$f(bit)$文件的副本所需时间。

![file_distribution](img/file_distribution.png)

​		$D_{cs}$表示C/S体系结构的分发时间，其中服务器需要上传$n$个文件的副本，则
$$
\begin{align}
D_{cs}&\geqslant max\{D_c,D_s\}\\&\geqslant max\{\frac{f}{d_{min}},\frac{nf}{u_s}\}
\end{align}
$$
​		$D_{P2P}$表示P2P体系结构的分发时间，分发开始时只有服务器有文件，分发一次后可由对等方来分发，则
$$
\begin{align}
D_{P2P}&\geqslant max\{D_c,D_s,\frac{nf}{u_{total}}\}\\&\geqslant max\{\frac{f}{d_{min}},\frac{f}{u_s},\frac{nf}{u_s+\sum_{i=1}^{n}u_i}\}
\end{align}
$$

##### 2.5.2 BitTorrent

​		参与文件分发的所有对等方的集合称为**洪流**。在一个洪流中的对等方彼此下载等大小的文件块，通常是256KB。每个洪流具有一个基础设施节点，称为**追踪器**。当有对等方加入洪流时需要向追踪器注册并周期性地通知是否在洪流中。

![file_distribution_with_bittorrent](img/file_distribution_with_bittorrent.png)

​		与对等方建立TCP连接的其他对等方称为该对等方的**邻居/邻近对等方**。

​		**最稀缺优先**即优先请求本身没有且邻居中副本最少的块。这样可以大致地均衡每个块在洪流中的副本量。

​		对等方优先响应那些当前能够以==最高速度==提供副本的邻居。对等方会每十秒进行速度测量并确定速度前四的邻居，这四个邻居会被**疏通**。此外，每三十秒会随机再选择一个邻居进行交换，如果彼此都能满足，则继续交换。除了这五个邻居，其他邻居将被阻塞，即无法从该对等方获取块。这种机制被称为**一报还一报**。

#### 2.6 CDN

##### 2.6.1 视频流

​		一张未压缩/数字编码的图像有像素阵列组成，每个像素由一些比特编码来表示亮度或颜色。

​		视频是一系列图像以每秒二十四/三十张图像来展现。视频能被压缩，故可以比特率来权衡视频质量。

​		在DASH中，视频编码为比特率不同的多个版本，每个版本都有一个不同的URL，每个版本的URL和比特率都存在HTTP服务器中的**告示文件**中。DASH运行客户端自由地切换版本。

##### 2.6.2 CDN

​		**CDN**分布在多个地理位置的服务器上，并且将用户请求重定向到一个时延更低的CDN。

​		CDN分为**专用CDN**和**第三方CDN**，专用CDN由内容提供商自身拥有，第三方CDN分发多个内容提供商的内容。

​		CDN通常采用**深入**和**客邀**这两种安置原则。

​		﹡深入由Akamai首创，该原则通过在遍及全球的接入ISP中部署服务器集群来深入到ISP的接入网中。其目标是靠近端系统，通过减少端系统和CDN集群之间的链路和路由器来减少时延和提供吞吐量，但也带来了较高的维护管理成本。

​		﹡客邀被Limelight和很多其他CDN公司采用，该原则通过在少量的关键位置(通常是因特网交换点)建立大量集群来客邀ISP。相比深入，客邀的维护管理成本更低，但时延较高而且吞吐量较低。

![dns_redirects_a_request_to_a_cdn_server](img/dns_redirects_a_request_to_a_cdn_server.png)

​		大多数CDN利用DNS来截获和重定向请求。

​		1）客户端访问某Web网页。

​		2）客户端访问该Web下的某个资源时，发送了对应的DNS请求。

​		3）本地DNS服务器将DNS请求中继到该Web的权威DNS服务器，权威DNS服务器返回了CDN域下的主机名。

​		4）本地DNS服务器通过CDN域下的主机名向CDN权威DNS服务器发送DNS请求，CDN权威DNS服务器返回了CDN服务器的IP地址。

​		5）本地DNS服务器将IP地址返回给客户端。

​		6）客户端通过IP地址与CDN服务器建立TCP连接并发送HTTP请求。

​		CDN部署的核心都是**集群选择策略**，即动态地将请求重定向到CDN中的某个服务器集群/数据中心。

​		较简单的选择策略是将请求重定向到(距离DNS服务器)**地理上最近**的集群。另一种选择策略是对DNS服务器和集群之间进行周期性的时延以及丢包**实时测量**来选择。

### 第三章 传输层

​		网络层提供了主机之间的逻辑通信，传输层提供不同主机的进程之间的逻辑通信。

​		运输层的**多路复用**与**多路分解**指将主机间交付扩展到进程间交换。

​		﹡多路复用指在不同套接字中收集数据块并为每个数据块封装上首部信息从而生成报文段再将报文段传递到网络层。

​		﹡多路分解指将传输层报文段中的数据交付到正确的套接字。

​		多路复用需要**源端口号字段**^【套接字的唯一标识符】^和**目的端口号字段**^【报文段中标识目标套接字的字段】^。

​		端口号是一个16位的数。0~1023之间的端口称为**周知端口号**。

​		**序号**用于为从发送端流向接收端的分组按序编号。

​		**校验和**用于分组的差错检测。

​		在信道中分组重新排序是可能的，可以表现为序号不存在于发送端和接收端的窗口中的分组/ACK的副本可能会出现。信道可以看成用来缓存分组，并在==任意时刻==释放这些分组。

​		通过设置分组的TTL来实现序号在发送端确定不会出现之前不会再被使用。

#### 3.1 UDP

​		UDP在发送报文段前传输层实体间没有握手，故UDP被称为==无连接==的。

![udp_segment_format](img/udp_segment_format.png)

​		UDP首部有四个字段，每个字段由2字节构成。

​		﹡长度字段即报文段中的字节数(首部+应用数据)。

![checksum_of_udp](img/checksum_of_udp.png)

​		伪首部包括源IP地址、目的IP地址、填充0的保留字段、传输层协议号以及报文长度。

​		发送端在计算校验和时需要先加上伪首部并将校验和字段置零，将伪首部、首部和应用数据转换成16位二进制(不足部分填充零)并求和，求和时需要回卷(如果进位到第17位则将结果加一)，将和取反得到校验和，发送端将设置校验和并去掉伪首部。接收端计算校验和方式类似于发送端(不需要将校验和置零)，最后结果全为一则说明数据无误，否则警告。

​		由于无法确保链路的可靠和内存中的差错检测，UDP在端到端基础上的传输层进行差错检测，这种设计被称为**端到端原则**，即同样功能的实现成本在较低级别相比较高级别可能较高。

#### 3.2 可靠数据传输

![reliable_data_transfer](img/reliable_data_transfer.png)

##### 3.2.1 rdt1.0

![fsm_of_rdt1.0](img/fsm_of_rdt1.0.png)

​		rdt1.0协议指经完全可靠信道的可靠数据传输，故接收端就不需要提供任何反馈信息给发送端。

​		FSM的初始状态用虚线表示。发送端和接收端的FSM都只有一个状态，故变迁必定是从一个状态返回到本身。

​		上层应用调用发送端的过程中，发送端只通过`rdt_send(data)`接收数据，经由`make_pkt(data)`产生一个包含该数据的分组，并将分组发送到信道中。

​		较低层协议调用接收端的过程中，接收端通过`rdt_rcv(packet)`从底层信道接收一个分组，经由`extract(packet,data)`取出数据，并通过`deliver_data(data)`将数据传输给上层。

##### 3.2.2 rdt2.0

​		通过**肯定确认**或**否定确认**来让发送端知道那些内容被正确接收或接收有误需要重传的可靠传输协议称为**自动重传请求**协议。自动重传请求协议还需要==差错检测==、==接收端反馈==^【用1位来表示，0是NAK，1是ACK】^和==重传==来处理比特差错的情况。

![fsm_of_rdt2.0.0](img/fsm_of_rdt2.0.png)

​		rdt2.0相比rdt1.0，加入了差错检测和肯定/否定确认。

​		当发送端等待ACK/NCK时不能从上层获取数据或发送分组，故rdt2.0被称为**停等**协议。

​		发送端有两个状态。在左边的状态中，发送端正在等待上层调用。当出现`rdt_send(data)`时，发送端将通过`make_pkt(data,checksum)`产生一个包含数据和校验和的分组，经由`udt_send(sndpkt)`发送该分组。在右边的状态中，发送端正在等待接收端回传的ACK/NAK。若收到ACK分组，即`rdt_rcv(rcvpkt) && isACK(rcvpkt)`，发送端会回到等待上层调用的状态。若收到NAK分组，即`rdt_rcv(rcvpkt) && isNAK(rcvpkt)`，发送端会重传分组并等待接收回传的ACK/NAK。

​		接收端只有一个状态。当分组到达时，接收端回传ACK/NAK，即`rdt_rcv(rcvpkt) && notcorrupt(rcvpkt)`或`rdt_rcv(rcvpkt) && corrupt(rcvpkt)`。

​		但是rdt2.0忽视了ACK/NAK分组受损的情况，解决这一问题的简单方法就是添加一个新字段来表示发送数据分组的序号。

![fsm_of_rdt2.1.png](img/fsm_of_rdt2.1.png)

​		rdt2.1是rdt2.0的修订版，rdt2.1的发送端和接收端FSM的状态数都是以前的两倍，因为需要反映出目前分组的序号。rdt2.1使用了接收端到发送端的ACK/NAK。当收到乱序的分组时，接收端回传ACK。当收到受损的分组时，接收端回传NAK。

![fsm_of_rdt2.2](img/fsm_of_rdt2.2.png)

​		rdt2.2相比rdt2.1，rdt2.2无NAK，而是对上一次正确接收的分组回传ACK。发送端收**冗余ACK**后，就知道了接收端没有正确接收到冗余ACK对应的分组后的分组。因此，ACK报文需要一个序号字段。

##### 3.2.3 rdt3.0

![fsm_of_rdt3.0_sender](img/fsm_of_rdt3.0_sender.png)

​		rdt3.0是用于具有比特差错的丢包信道的协议。通过在发送端中加入**倒数计时器**来解决超时/丢包问题，接收端与rdt2.2相同。

​		因为分组序号在0和1之间交替，rdt3.0也被称为**比特交替协议**。

##### 3.2.4 流水线可靠数据传输协议

![stop-and-wait_and_pipelined_sending](img/stop-and-wait_and_pipelined_sending.png)

​		停等协议存在一定的性能问题，简单的解决方式就是不使用停等，允许发送方发送多个分组而无须等待。因为许多从发送端到接收端的分组可以被看出是填充到一条流水线，故这种技术被称为**流水线**。

​		流水线需要可靠数据传输协议增加序号的范围和发送/接收端缓存分组，而这些取决于差错恢复。流水线的差错恢复包括**回退N步**和**选择重传**。

##### 3.2.5 回退N步

![sender_view_of_sequence_numbers_in_gbn](img/sender_view_of_sequence_numbers_in_gbn.png)

​		随着协议的运行，该窗口的序号空间向前滑动，故$N$被称为窗口长度，GBN也被称为滑动窗口协议。

​		$base$表示最早待确认的分组的序号，$nextseqnum$表示最早的待发送的分组的序号。

​		$[0,base-1]$表示已被确认的分组，$[base,nextseqnum-1]$表示待确认的分组，$[nextseqnum,nextnum+N-1]$表示待发送的分组，$[nextnum+N,+\infty)$表示不可用的分组，直到当前流水线中待确认的分组确认。

![extended_fsm_of_gbn](img/extended_fsm_of_gbn.png)

​		发送端必须响应==上层的调用==、==接收ACK==和==处理超时==。

​		当上层调用`rdt_send()`时，发送端先检测发送窗口是否已满。若窗口未满则产生一个分组发送并更新对应的变量，反之则反馈上层。不存在待确认分组的情况下首次发送分组时会设置一个计时器。当收到ACK但仍存在待确认的分组时，计时器将重置。当不存在待确认的分组时停止计时器。

​		接收端用$expectedseqnum$来表示按序待接收的分组的序号。

​		接收端对序号为$n$的分组使用**累积确认**的方式，表明已正确收到序号在$n$之前且包括$n$的所有分组。

​		当接收端收到序号为$n$的分组且上次交付给上层的分组的序号是$n-1$时会对分组$n$回传ACK，否则丢弃该分组并对最近交付给上层的分组回传ACK。

​		接收端会丢失所有乱序分组，因为这些分组还会重传。

![gbn_operation](img/gbn_operation.png)

##### 3.2.6 选择重传

![sender_and_receiver_views_of_sequence_numbers_in_sr](img/sender_and_receiver_views_of_sequence_numbers_in_sr.png)

​		发送端仅重传那些在接收方可能丢失/受损的分组，也可能收到窗口内某些分组的ACK。

​		接收端将确认一个正确接收的分组而不管是否按序，乱序的分组将被缓存，当所有的乱序分组都被接收后再一起交付给上层。

​		当上层调用`rdt_send()`时，发送端检测可用于分组的序号是否在窗口内。若在窗口内则产生一个分组发送，反之则反馈上层。每个分组都有一个计时器。当收到ACK时，若ACK对应的分组序号在窗口内则将该分组标记为已确认，若ACK对应的分组序号等于$send\_base$则将窗口移动至待确认的最小序号处。窗口移动后且窗口内存在待发送的分组，这些分组将被发送。

​		对接收端，==序号在$[rcv\_base-N,rcv\_base+N-1]$内的分组将被正确接收==。若接收分组的序号在窗口内将回传ACK，分组首次接收时缓存该分组。若接收分组的序号等于$rcv\_base$，则该分组以及缓存中序号始于该分组的序号且连续的所有分组将交付给上层。若接收分组的序号在$[rcv\_base-N,rcv\_base-1]$，则==必须==回传一个ACK，无论该分组是否已被确认。

![sr_operation](img/sr_operation.png)

​		SR问题在于发送端/接收端之间缺乏同步，唯一能确定的是只有信道中收到的分组/ACK。

![problem_of_sr](img/problem_of_sr.png)

​		SR的窗口长度必须小于或等于序号去重后的数量的一半。

#### 3.3 拥塞控制原理

##### 3.3.1 拥塞原因与代价

![two_senders_and_a_router_with_infinite_buffers](img/two_senders_and_a_router_with_infinite_buffers.png)

​		$\lambda_{in} (B/s)$表示应用层通过套接字发送初始报文到传输层的速度，$\lambda_{out} (B/s)$表示应用层接收报文的速度。

​		分组通过一台路由器在容量为$R$的共享式输出链路上传输，忽略添加底层首部信息的开销、差错恢复、流量控制和拥塞控制，显然$\lambda_{out} \leqslant \frac{R}{2}$ 。时延的增长率随着$\lambda_{in}$增长，$\lambda_{in}$达到$\frac{R}{2}$时时延无穷大。这里体现了==拥塞的代价之一：当分组的到达速度接近链路容量时，分组承受巨大的排队时延==。

![two_senders_with_retransmissions_and_a_router_with_finite_buffers](img/two_senders_with_retransmissions_and_a_router_with_finite_buffers.png)

​		$\lambda^{'}_{in} (B/s)$表示传输层发送初始报文段和重传报文段到网络层的速度，也称为**供给载荷**。

​		假设发送端能确定路由器的可用缓存并根据情况发送分组，所以不会丢包，$\lambda_{in}=\lambda^{'}_{in}$，连接的吞吐量为$\lambda^{'}_{in}$。在这种情况下，平均主机发送速度不能超过$\frac{R}{2}$。

​		假设发送端仅确定分组丢失后下才重传，当$\lambda_{in}^{'}=\frac{R}{2}$且平均时 $\lambda_{in}=\lambda_{out}=\frac{R}{3}$。这里体现了==拥塞的代价之一：发送端必须重传因缓存溢出而丢失的分组==。

​		假设发送端重传因排队时延超时但未丢失的分组，当$\lambda_{in}^{'}=\frac{R}{2}$且平均(转发两次)时$\lambda_{in}=\lambda_{out}=\frac{R}{4}$。这里体现了==拥塞的代价之一：发送方因较大的时延进行了不必要的重传来占用路由器额外的链路带宽==。

![four_senders_with_retransmissions,routers_with_finite_buffers](img/four_senders_with_retransmissions,routers_with_finite_buffers.png)

​		当$\lambda_{in}$较小时，路由器缓存比较充足，吞吐量大致等于供给载荷，$\lambda_{out}$随着$\lambda_{in}$增大而增大。当$\lambda_{in}$较大时，对于R2，主机B发送的分组的到达速度高于主机A发送的分组的到达速度，这会导致主机A发送的分组因缓存溢出而丢失。

​		若考虑网络资源的浪费，当分组在第二跳及之后的路由器丢失时，之前路由器的转发工作毫无意义。这里体现==拥塞的代价之一：分组被丢弃时转发过该分组的上游路由器因转发而使用的传输容量被浪费==。

##### 3.3.2 拥塞控制方法

​		根据网络层是否为传输层提供了显示支持可将拥塞控制分为==端到端拥塞控制==和==网络辅助拥塞控制==。

​		在端到端拥塞控制中，网络层==没有==为传输层提供显示支持。即使网络中存在拥塞，端系统也必须通过对丢包和时延等网络行为的观察来确定是否拥塞。

​		在网络辅助的拥塞控制中，路由器向发送端提供关于的拥塞状态的显示反馈信息。拥塞信息反馈到发送端通常有两种方式，一种是路由器直接发送关于拥塞状态的分组给发送端，此时该分组称为**抑制分组**。另一种方式更通用，TCP、DCCP和DCTCP都有使用。路由器更新==由发送端到接收端的数据报头部中的ECN拥塞标志位==来表示出现拥塞。若接收端收到分组的标志位表示出现拥塞则会通知发送端，故这种方式至少需要一个完整的往返周期。

#### 3.4 TCP

​		在进程发送数据之前，进程间必须握手，即相互发送一些预备报文段来设置确保数据传输的参数，故TCP是**面向连接的**。

​		TCP连接只能有一个客户端和一个服务器，故TCP是**点对点**的。

​		进程间建立TCP连接后，双方都可以发送/接收报文段，故TCP是**全双工服务**。

​		TCP根据ACK到达的速度来调节拥塞窗口，故TCP是**自计时**的。

​		客户端先发送一个特殊的报文段，服务器用另一个特殊报文段来响应，最后，客户端用第三个特殊报文段作为响应，这种建立连接的过程被称为**三次握手**。前2个报文段不承载有效载荷，第三个报文段可以承载有效载荷。

​		TCP的双方都由一个接收缓存、一个发送缓存和几个变量组成。

​		TCP会使用**重传计时器**、**坚持计时器**、**保活计时器**和**时间等待计时器**这四种计时器。重传计时器用于报文段重传。坚持计时器用于防止双方的死锁。保活计时器用于在长连接中断开无响应的连接。时间等待计时器用于四次握手断开连接前的等待。

​		**最大传输单元**指从源到目的地所有链路上发送的最大链路层帧。**最大报文段长度**是报文段中有效载荷的最大长度。最大传输单元一般是1500字节，TCP/IP首部的长度一般是40字节，故最大报文段长度一般是1460字节。

​		当收到按序报文段时，若序号在按序报文段之前的报文段都已经确认，则等待下一个按序报文段最多500ms，超时则发送ACK。若还存在另一个按序报文段待确认，则立即发送单个累积ACK来确认这两个报文段。

​		当收到序号在按序报文段之后的报文段时则立即发送冗余ACK。

​		一旦收到3个冗余ACK，TCP就执行**快速重传**。

​		当==超时或收到3个冗余ACK==时，发送端出现了丢包。

​		TCP的差错恢复机制是**选择性确认**，即有选择地确认乱序报文段。

##### 3.4.1 TCP报文段

![tcp_segment_format](img/tcp_segment_format.png)

​		TCP报文段包括16位**源端口**、16位**目的端口**、32位**序号**、32位**确认序号**、4位**首部长度**、3位保留字段、9个标志位、16位**窗口长度**、16位**校验和**、16位**紧急指针**以及最多40字节的的选项字段。

​		TCP将数据看成一个无结构且有序的字节流，通过字节流确定序号，序号是==报文段首字节的编号==。初始序号一般随机。

​		确认号是==下一次按序应接收报文段首字节的编号==。TCP只确认报文段有效载荷中到第一个丢失字节为止的字节，故TCP提供**累积确认**。当有效载荷为空时吗，确认号被**捎带**在报文段中。

​		9个标志位中第2、3位标志位用于显式拥塞控制，若发送端至接收端链路中的某个路由器出现拥塞，当数据报达到该路由器后，路由器将数据报头部中的ECN标识为置1，接收端收到数据报后将ACK报文段头部中的`ECE`置1来通知发送端链路出现拥塞，发送端像快速重传一样对`ECE`为1的ACK回应ACK，发送端在下一个报文段中将`CWR`置1来通知接收端拥塞窗口已缩减。后6个标志是控制位。

​		﹡**NS/N**通常用于防止标记数据包被意外或恶意地隐藏。

​		﹡**CWR/C**为1时通知对方拥塞窗口已缩减。

​		﹡**ECE/E**为1时通知对方链路出现拥塞。

​		﹡**Urgent/URG/U**为1时表示高优先级报文段，紧急指针生效。

​		﹡**ACK/A**为1时表示确认序号生效，报文段成功接收。

​		﹡**Push/PSH/P**为1时表示应该立即将该报文段交给应用层而不用等待缓存区填满。

​		﹡**Reset/RST/R**为1时表示重置连接。

​		﹡**Synchronization/SYN/S**为1时表示三次握手中建立连接。

​		﹡**Finish/FIN/F**为1时表示四次挥手中断开连接。

​		选项字段包括8位Kind、可变的Length以及可变的Info。

| Kind字段值 | Length字段值 | Info字段长度 | 名称                       | 含义           |
| ---------- | ------------ | ------------ | -------------------------- | -------------- |
| 0          | 1            |              | 选项表结束(EOP)            |                |
| 1          | 1            |              | 空操作(NOP)                |                |
| 2          | 4            | 2字节        | 最大报文段长度(MSS)        |                |
| 3          | 3            | 1字节        | 窗口扩大系数(WSOPT)        | 窗口长度扩展   |
| 4          | 2            |              | 选择性确认(SACK-Premitted) | 表示支持SACK   |
| 5          | 可变         |              | 选择性确认(SACK)           | 收到的乱序数据 |
| 8          | 10           |              | TSPOT                      | 时间戳         |
| 19         | 18           |              | TCP-MD5                    | MD5认证        |
| 28         | 4            |              | User Timeout(UTO)          | 超时时间       |
| 29         | 可变         |              | TCP-AO                     | 认证算法       |
| 253/254    | 可变         |              | Experimental               | 保留           |

​		窗口长度用于流量控制服务。

​		校验和的计算与UDP相同。

##### 3.4.2 连接管理

![three-way_handshake](img/three-way_handshake.png)

​		1）客户端向服务器发送**SYN(报文段)**，即报文段的有效载荷为空，`SYN`为1，客户端进入`SYN_SENT`。

​		2）服务器收到SYN后为该连接分配TCP缓存和变量，再向客户端发送**SYNACK(报文段)**，即ACK报文段的`SYN`为1，最后服务器进入`SYN_RCVD`。

​		3）客户端收到SYNACK后该连接分配TCP缓存和变量，再向服务器发送ACK，此时连接已建立，`SYN`置为0，最后服务器进入`ESTABLISHED`。服务器收到ACK后进入`ESTABLISHED`。

![four-way_handshake](img/four-way_handshake.png)

​		1）客户端向服务器发送**FIN(报文段)**，即报文段的有效载荷为空，`FIN`为1，客户端进入`FIN_WAIT_1`。

​		2）服务器收到FIN后发送ACK并进入`CLOSE_WAIT`。客户端收到ACK后进入`FIN_WAIT_2`。

​		3）服务器向客户端发送FIN并进入`LAST_ACK`。

​		4）客户端收到FIN后发送ACK并进入`TIME_wAIT`，同时设置时间等待计时器，到时后释放资源(包括端口号)并进入`CLOSED`。服务器收到ACK后释放资源并进入`CLOSED`。

![tcp_state](img/tcp_state.png)

​		在TCP连接的生命周期中，运行在每台主机的TCP协议会在各种**TCP状态**间变迁。

##### 3.4.3 超时

​		SampleRTT表示报文段从发送(交付给IP)到收到该报文段的确认所需时间。TCP不会为重传的报文段测量SampleRTT，仅仅为只需要传输一次的报文段测量。

​		EstimatedRTT表示SampleRTT的平均值。
$$
EstimatedRTT=(1-\alpha)\times EstimatedRTT+ \alpha \times SampleRTT(\alpha =\frac{1}{8})
$$
​		DevRTT表示SampleRTT偏离EstimatedRTT的程度。
$$
DevRTT=(1-\beta)\times DevRTT+\beta \times |SampleRTT-EstimatedRTT|(\beta=\frac{1}{4})
$$
​		EstimatedRTT和DevRTT的计算方式是**指数加权移动平均**。

​		TimeoutInterval表示超时时间，公式为$TimeoutInterval=EstimatedRTT+4\times DevRTT$。

##### 3.4.4 流量控制

​		TCP用**流量控制服务**来使发送端的发送速度和接收端的读取速度相匹配，这一服务通过让==发送端==维护**接收窗口**^【表示接收端可用缓存空间】^的变量来实现。

​		$RevBuffer$表示接收端的接收缓存的大小。$LastByteRead$表示接收端在接收缓存中读取的数据流的最后一个字节的编号。$LastByteRcvd$表示接收端缓存至接收缓存的数据流的最后一个字节的编号。$rwnd$表示接收窗口。
$$
rwnd=RcvBuffer-[LastByteRcvd-LastByteRead]
$$
​		接收端将报文段中窗口长度字段设置为$rwnd$来告知发送端可用缓存空间。

​		$LastByteSent-LastByteAcked$表示发送端待确认的数据量。
$$
LastByteSent-LastByteAcked\leqslant rwnd
$$
![deadlock_of_tcp](img/deadlock_of_tcp.png)

​		当发送端收到的窗口长度为零的ACK时，会设置坚持计时器并发送一个有效载荷为一字节的探测报文段，若计时器超时或收到ACK的窗口长度为零时会再次发送同样的报文段并重置计时器，反之则继续发送有效载荷为有效数据的报文段。

##### 3.4.5 TCP拥塞控制

​		网络层不向端系统提供显示的网络拥塞反馈，故TCP只能使用端到端拥塞控制。

​		TCP发送端相比接收端多个变量，即**拥塞窗口**，用来限制发送速度。发送端未被确认的数据不能超过接收窗口与拥塞窗口的最小值。
$$
LastByteSent-LastByteAcked \leqslant min\{cwnd,rwnd\}
$$
​		假设接收窗口足够大、忽略丢包与时延以及发送端总有数据需要发送，==发送速度大致等于$\frac{cwnd}{RTT}(B/s)$==。

​		当某路径出现拥塞时，该路径上的一/多个路由器的缓存会溢出并导致某个数据包丢失，进而引发发送端的丢包，此时发送端可以确定该路径出现了拥塞。

​		==带宽探测：丢包表示出现了拥塞，应该降低发送速度。当未确认报文段的ACK到达时应该提高发送速度。==

###### 3.4.5.1 TCP拥塞控制算法

​		TCP拥塞控制算法包括**慢启动**、**拥塞避免**和**快速恢复**。

​		TCP拥塞控制被称为**加性增、乘性减**拥塞控制方式。加性增指在拥塞避免阶段$cwnd$的线性增加，乘性减指进入快速恢复阶段时$cwnd$的减半，若结果不是整数则向下取整。

![fsm_of_tcp_congestion_control](img/fsm_of_tcp_congestion_control.png)

​		在慢启动阶段，$cwnd$的初始值是$MSS$，$ssthresh$的初始值是$64KB$。每当报文段首次确认$cwnd$就增加$MSS$，即指数级增长。若出现超时导致的丢包，发送端令$ssthresh=\frac{cwnd}{2}$，$cwnd=MSS$并重新开始慢启动。当$cwnd \geqslant ssthresh$时发送端结束慢启动并进入拥塞避免阶段。当收到3个冗余ACK时，发送端结束慢启动并令$ssthresh=\frac{cwnd}{2}$，$cwnd=\frac{ssthresh}{2}+3MSS$，然后执行快速重传，最后进入快速恢复阶段。

​		在不考虑处理时间的情况下，客户端发送请求到远程数据中心并收到响应大致需要$4RTT$，其中建立TCP需要$RTT$，慢启动阶段需要$3RTT$。显然，当$RTT$较大时，时延也较大。可以使用**TCP分岔**解决这一问题，即通过CDN将请求转发至邻近客户端且与远程数据中心有很大窗口的连接的前端服务器，在这种情况下响应所需时间大致是$4RTT_{FE}+RTT_{BE}+处理时间$，其中$RTT_{FE}$表示客户端与前端服务器的往返时间，$RTT_{BE}$表示前端服务器与远程数据中心的往返时间。当前端服务器与客户端足够近，就可以忽略$RTT_{FE}$，此时响应所需时间大致等于$RTT$。

​		在拥塞避免阶段，每个$RTT$内$cwnd$仅增加$MSS$。通用实现方法是若$RTT$内发送了$n$个报文段，在此期间每个报文段首次确认时$cwnd$增加$\frac{cwnd}{n}$。超时和3个冗余ACK的情况同慢启动。

​		在快速恢复阶段，每收到一个冗余ACK，$cwnd$增加$MSS$。当收到了新报文段的首次ACK，发送端会结束快速恢复阶段并进入拥塞避免阶段。当出现超时导致的丢包时发送端会结束快速恢复并令$ssthresh=\frac{cwnd}{2}$，$cwnd=MSS$，然后进入慢启动阶段。

![evolution_of_tcp_congestion_window](img/evolution_of_tcp_congestion_window.png)

​		TCP的较新版本**TCP Reno**的快速恢复阶段符合上述情况。但TCP的早期版本**TCP Tahoe**在快速恢复阶段只要出现丢包都会结束快速恢复并令$ssthresh=\frac{cwnd}{2}$，$cwnd=MSS$，然后进入慢启动阶段。

​		TCP Vegas试图在维持较好吞吐量同时避免拥塞，通过测量RTT来衡量拥塞程度，根据拥塞程度线性地降低发送速度。TCP Vegas提供了慢启动、拥塞避免、快速恢复、快速重传和SACK。

###### 3.4.5.2 平均吞吐量

​		当计算一个吞吐量较大的连接的平均吞吐量时，因为慢启动阶段和快速恢复阶段通常很短，都可以忽略，故可以认为该连接处于拥塞避免阶段。在一个RTT内，窗口长度是$w(B)$，吞吐量大约是$\frac{w}{RTT}$。在出现丢包之前，每个RTT内$w=w+MSS$。用$W$表示出现丢包时$w$的值。

​		若在一段时间内吞吐量从$\frac{W}{2RTT}$线性增长到$\frac{W}{RTT}$，丢包仅出现了一次且发生在最后。
$$
\begin{align}
Segment_{total}&=\frac{W}{2RTT}\times RTT+\frac{W+2}{2RTT}\times RTT+\cdots +\frac{W}{RTT}\times RTT\\
&=(\frac{W}{4}+\frac{W}{2}) \times (\frac{W}{4}+\frac{1}{2})\\
&=\frac{3W^2}{8}+\frac{3W}{4}\\
\end{align}
$$
​		丢包率$L=\frac{Segment_{loss}}{Segment_{total}}$。
$$
\begin{align}
L&=\frac{1}{Segment_{total}}\\
&=\frac{1}{\frac{3W^2}{8}+\frac{3W}{4}}\\
&=\frac{8}{3W^2+6W}
\end{align}
$$
​		由于${3W^2}>>{6W}$，$6W$可以忽略，故$W \approx \sqrt{\frac{8}{3L}}$。由于增长是线性，平均吞吐量是$\frac{3W}{4RTT}(MSS)$。
$$
\begin{align}
平均吞吐量&=\frac{\sqrt{6}MSS}{2RTT\sqrt{L}}\\
&\approx \frac{1.22\times MSS}{RTT\sqrt{L}}
\end{align}
$$

###### 3.4.5.3 公平性

​		**瓶颈链路**指沿着某连接路径上的每条连接都不拥塞且相比该链路的传输容量都具有足够的传输容量。

​		假设$K$条TCP连接每条的端到端路径不同，但是都经过一段传输速率为$R(b/s)$的瓶颈链路。若每条连接都在传输一个大文件且无UDP流量通过该链路，而且每条连接的平均传输速度接近$\frac{R}{K}$，则认为该拥塞控制机制是**公平**的。在这种理想情况下，当所有连接的RTT相同时才能平等共享带宽。实际上这些条件不能满足，具有较小RTT的连接可以更快地扩大拥塞窗口。

​		UDP并没有内置的拥塞控制机制，UDP是不公平的，UDP可能抑制TCP。

​		当一个应用使用多条并行TCP连接时，对单条TCP连接可能是公平的，但对应用并不公平。

### 第四章 网络层

​		网络层提供的服务是**尽力而为服务**。

​		**转发**是指将分组从一个输入链路接口转移到适当的输出链路接口的路由器本地动作。转发所需时间通常为几纳秒，故通过硬件实现。

​		**路由选择**是指确定数据报从源到目的地的端到端路径的网络范围处理过程。路由选择所需时间通常为几秒，故通过软件来实现。

​		网络层可以分为**数据平面**和**控制平面**。

​		﹡数据平面即==路由器的功能==，用于从路由器的输入链路向输出链路转发分组，包括传统的==IP地址转发==和==通用转发==。两者都采用匹配加动作的模式，匹配是匹配分组，动作是匹配之后的动作，区别在于IP地址转发是根据IP地址匹配，而通用转发是根据协议栈对多个首部字段进行匹配。

​		﹡控制平面即==网络范围的逻辑==，用于协调路由器间的转发动作，使得分组最终沿着源主机和目的主机之间的路径进行端到端传输。可以通过传统的**每路由器控制**(每台都有转发和路由选择功能，每台路由器还有一个路由选择组件，该组件与其他路由器中的路由组件通信以计算转发表的值)和**SDN控制**(逻辑集中控制器计算并分发转发表给每台路由器)来构建控制平面。

​		**网络服务模型**定义了分组在发送与接收端系统之间的端到端运输特性。

​		主机与物理链路之间之间的边界叫做**接口**。路由器与其任意一条链路之间的边界也叫做接口，例如输入端口或输出端口。在技术层面上，一个IP地址与一个接口相关，而不是与包括该接口的主机/路由器相关。在公网中，除NAT接口之外的每台主机/路由器的每个接口都必须有个公网IP地址。

​		IP地址一般划分为网络地址和主机地址。主机地址不能全为0/1，主机地址全为0的地址是网络地址，主机地址全为1的地址是广播地址。

​		**子网掩码**用来区分IP地址的网络地址和主机地址，故必须与IP地址结合使用。子网掩码的网络地址全为1，主机地址全为0。

​		第一跳路由器的IP地址称为**默认网关**。

![nat](img/nat.png)

​		**网络地址转换**是将数据报中的IP地址转换成另一个IP地址，主要用于实现内网访问公网的功能。

​		在因特网中每个**自治系统**由一组受相同管理控制的路由器组成，通常在一个ISP中的路由器以及互联它们的链路构成一个自治系统。自治系统由全局唯一的AS号(ASN)所标识。在同一自治系统中的路由器运行相同的路由选择算法并有彼此的信息。

​		在一个自治系统内运行的路由选择协议称为**自治系统内部路由选择协议**。自治系统间的路由选择协议称为**自治系统间路由选择协议**。两者的差别主要体现在策略、规模以及性能这三个方面。

​		﹡从策略的角度，AS内部都在同一管理控制下，策略在AS内部路由选择中起着微不足道的作用；AS间路由选择承载了路径属性并提供路由信息的受控分布，以便能做出基于策略的路由选择决策。

​		﹡从规模的角度，规模不是AS内部路由选择的关注重点，但它是AS间路由选择协议的关键问题。

​		﹡从性能的角度，AS内部路由选择协议注重路由的性能；AS间路由选择是面向策略的，因此所选路由的性能是次要问题。

​		因特网中所有AS运行相同的AS间路由选择协议，即**边界网关协议**，边界网关协议还常用于实现**IP任播**。

​		**存根网络**又称为桩网络或末端网络，指仅有一条(默认)路径连接到其他网络。

​		**网络功能虚拟化**指将用服务器、交换机和存储设备来代替复杂的中间盒。

#### 4.1 路由器

![router_architecture](img/router_architecture.png)

​		线路端接的功能是结束传入物理链路的物理层功能。

​		数据链路处理的功能是与位于传入链路远端的数据链路层交互的数据链路层功能。

​		当一条链路是双向时，输入端口和输出端口通常成对出现在同一线路卡上。

##### 4.1.1 IP地址转发

​		每台路由器都有**转发表**。路由选择处理器通过使用路由选择协议与其他路由器中的路由选择处理器交互来计算/更新转发表。在SDN路由器中，路由选择处理器用来接收远程控制器计算的转发表项更新转发表。

​		路由选择处理器经过独立总线将转发表复制到线路卡。通过转发表的副本，每个输入端口就可以本地完成转发，避免了集中式处理的瓶颈。

​		路由器根据分组目的地址的**前缀**与转发表中的表现进行匹配。当有多个匹配项时，路由器使用**最长前缀匹配规则**。

​		可以使用**三态内容寻址存储器**来保证查询转发表所需时间维持在一个常数内。

​		找到分组的输出端口后，分组就可以进入交换结构了，但如果该输出端口已被占用，分组可能在进入交换结构前暂时阻塞。

##### 4.1.2 交换结构

![three_switching_techniques](img/three_switching_techniques.png)

​		﹡==经内存交换==：最简单、最早的路由器是传统的计算机，输入端口与输出端口之间的交换是在CPU(路由选择处理器)的直接控制下完成的。输入/输出端口的功能就像传统操作系统中的I/O设备一样。当分组到达到达一个输入端口时，该端口先通过中断方式向路由选择控制器发送信号，该分组从输入端口复制到内存，路由选择处理器从分组首部中获取IP，查询转发表获取输出端口并将分组复制到输出端口的缓存中。若内存每秒能读/写$B$个分组，则总转发吞吐量必定小于$\frac{B}{2}$，因为共享系统总线每次仅能执行一个内存读/写。

​		﹡==经总线交换==：输入端口经一根共享总线将分组直接传输到输出端口，不需要路由选择控制器的干预。输入端口预先为分组指定一个交换机内部标签(首部)^【仅用来跨越总线】^并指示输出端口。每个输出端口都能收到该分组，但只有指定的输出端口才能保存该分组，指定的输出端口保存分组后去掉标签。每次仅有一个分组能跨域总线，故分组有时需要等待，导致路由器的带宽受限于总线速度。

​		﹡==经互联网络交换==：纵横式交换机是由$2N$条总线构成的互联网络，包括$N$个输入端口和$N$个输出端口。每条垂直的总线与每条水平的总线交叉，交叉点通过交换结构控制器实现随时开启/闭合。纵横式交换机是**非阻塞**的，只有两个或以上的分组同时转发到同一个输出端口，分组不会阻塞，反之则会出现分组等待。

​		部分现代路由器也通过内存进行交换，不过转发表的查找和将分组存储进适当的内存存储位置是由输入线路卡来处理。

​		更复杂的互联网络使用多级交换元素来使多个分组同时转发到同一输出端口时无需等待。例如三级非阻塞交换策略，在这种策略中，输入/输出端口连接到$N$个交换结构，输入端口将分组分成$K$个较小的块并通过$N$个交换结构发送这$K$个块到指定输出端口，输出端口再将这$K$个块组装成原本的分组。

##### 4.1.3 排队

​		假设纵横式交换机有$N$个输入端口和$N$个输出端口且输入线路与输入线路速度相同，都为$R_{line}(packet/s)$。此外，所有分组具有相同的固定长度，以同步的方式到达输入端口且采用FCFS方式，即所有链路发送/接收分组的时间相等。用$R_{switch}$表示分组从输入端口传输到输出端口的速度。再假设$R_{switch}=N\times R_{line}$。

![hol_blocking](img/hol_blocking.png)

​		一个输入队列中排队的分组阻塞后，队列中该分组之后的分组也会阻塞，这种情况称为**线路前部阻塞**。由于HOL阻塞，当输入链路接收分组的度达到其容量的$58\%$时，在某些假设前提下，输入端口的队列长度将无限制地增大。

![output_port_queueing](img/output_port_queueing.png)

​		当没有足够缓存时，要么丢弃到达的分组(即弃尾策略)，要么删除排队中的分组。在某些情况下，在缓存填满之前便丢弃分组或在其首部加上标记，这可以向发送端反馈拥塞信号，这种策略称为**主动队列管理**策略。RED算法就算最广泛研究与实现的AQM算法之一。

​		$B$表示缓存容量，$C$表示链路容量，通常$B=RTT\times C$，当大量TCP流量经过同一链路时$B=\frac{RTT\times C}{\sqrt{N}}$。

##### 4.1.4 分组调度

![fifo_or_fcfs_queueing_model](img/fifo_or_fcfs_queueing_model.png)

​		FIFO/FCFS调度规则安装分组到达输出链路队列的顺序来传输分组。当链路正忙于传输其他分组时，到达链路输出队列的分组需要排队等待传输。若缓存不足则需要丢弃分组。

![priority_queueing_model](img/priority_queueing_model.png)

​		在**优先级排队**规则下，到达输出链路的分组被分类放入输出队列的优先级类，同一优先级采用FIFO方式。在非抢占式式优先级排队规则下，一旦分组开始传输就不能打断。

![weighted_fair_queueing_model](img/weighted_fair_queueing_model.png)

​		在**循环排队**规则下，分组会被分类，但是类之间不存在严格的优先级，循环调度器在这些类之间轮流提供服务。在**保持工作排队**规则下，有分组待传输时不会允许链路空闲，当指定类里不存在分组时，会立即检查循环序列中的下一个类。**加权公平排队**就是循环排队的一种通用实现方式，它也是保持工作队列。

​		WFQ与循环排队的不同之处在于每个类在任何时间间隔内可能收到==不同数量==的服务。对于WFQ，若有$n$个类存在分组待传输，类$i$的权值为$w_i$，即使所有类都有分组排队，类$i$总能保证至少$\frac{w_i}{\sum_{j=1}^{n}{w_j}}\times R$的吞吐量。

#### 4.2 网际协议

##### 4.2.1 IPv4数据报

![ipv4_datagram_format](img/ipv4_datagram_format.png)

​		IPv4数据报包括4位的**版本(号)**、4位的**首部长度**、8位的**服务类型**(3位优先级、4位服务类型子字段和1位必须为零)、16位的**数据报长度**、16位的**标识**、3个**标志位**、13位的**片偏移**、8位的**生存时间**、8位的**上层协议**、16位的**首部检验和**、32位的**源IP地址**、32位的**目的IP地址**、最多40字节的**可选项**和有效载荷。

​		版本规定了IP协议版本。由于不同版本的IP协议数据报格式不同，需要版本字段来确定。

​		首部长度==以4字节为单位==表示首部长度。

​		服务类型用来区分不同类型的数据报。前3位是优先级字段，第4位到第6位是DTR字段，第4位到第7位是服务类型子字段，最后一位必须为零。服务类型子字段最多只能有1位为1。

| 优先级 | 名称                 | 含义             |
| ------ | -------------------- | ---------------- |
| 000    | routine              | 默认             |
| 001    | priority             | 数据业务         |
| 010    | immediate            | 数据业务         |
| 011    | flash                | 语音控制数据     |
| 100    | flash override       | 视频会议或视频流 |
| 101    | critic               | 语音数据         |
| 110    | internetwork control | 网络控制数据     |
| 111    | network control      | 网络控制数据     |

| 服务类型子字段 | 名称                   |
| -------------- | ---------------------- |
| 0000           | normal service         |
| 1000           | minimize delay         |
| 0100           | maximize throughout    |
| 0010           | maximize reliability   |
| 0001           | minimize monetary cost |

​		生存时间表示数据报能经过的最大路由器数量，每当路由器处理数据报时该字段值减1，当该字段值为0时丢弃该数据报。

​		由于源到目的地路径的上的每段链路可能使用不同的链路层协议，不同协议的最大传输单元可能不同，所以可能需要将数据报分成多个较小的数据报并封装成合适的链路层帧，这些较小的数据报称为**片**。片到达目的地后需要重组成原始数据报再交给传输层。重组过程在端系统完成，因为组装会给增加协议复杂性和降低路由器的性能。

![ipv4_datagram_fragmentation](img/ipv4_datagram_fragmentation.png)

​		标识、标志位以及片偏移用于分片和重组。标识是数据报的唯一值，分片时会复制到各个片中。3个标志位中第1位是保留位，第2位是禁止分片标志位，第3位是还有分片标志。DF为1时表示不能分片，MF为1时表示不是最后一个片。片偏移==以8字节为单位==表示片在原始数据报中的相对位置。

​		上层协议表示传输层所用协议的协议号。1表示ICMP，2表示IGMP，6表示TCP，17表示UDP，89表示OSPF。

​		首部校验和==仅用来校验数据报中的首部==，计算方式类似于UDP的校验和计算。由于每次经过路由器时首部中的某些字段会改变，所以需要重新计算。

##### 4.2.2 IPv4编址

​		每个IPv4地址长度是32位，因此共有$2^{32}$个可能的IP地址。IP地址通常使用**点分十进制表示法**。

![ipv4_classful_addressing](img/ipv4_classful_addressing.png)

​		IPv4**分类编制**包括A、B、C三类普通地址以及D、E两类特殊地址。A类地址一般用于大型网络，B类地址一般用于中型网络，C型地址一般用于小型网络，D类地址是多播地址，E类地址是保留地址。

​		`255.255.255.255`是广播地址，表示使用广播的方式，若数据报的目的IP地址是该IP地址，最后封装成帧后会广播到该网络下所有节点。

​		因特网的地址分配策略称为**无类别域间路由选择**。CIDR不在使用分类编址，IP地址表示为`a.b.c.d/x`。`x`表示网络地址所占的位数，该部分称为该地址的**前缀**，剩余的几位则表示主机地址。其地址掩码依然是子网掩码。使用单个网络前缀通告多个网络称为**地址聚合**或**路由聚合**或**路由摘要**。

##### 4.2.3 DHCP

​		**动态主机配置协议**允许主机自动获得IP地址、子网掩码、默认网关以及本地DNS服务器地址，故它也称为**即插即用协议**或**零配置协议**。DHCP是C/S体系结构，客户端即新到达的主机，若子网没有DHCP服务器则会由一个通常是路由器的DHCP中继代理，中继代理能够获取DHCP服务器。

​		DHCP分配IP地址包括**人工配置**、**自动配置**和**动态配置**。人工配置即管理员手动分配。自动配置即服务器为首次连接网络的客户端分配一个永久IP地址，客户端一直使用该IP地址。动态配置即按服务器为首次连接网络的客户端分配一个期限IP地址，到期后停止使用或续约。

​		DHCP租约表包括**静态租约表**和**动态租约表**，分别对应静态租约存储文件和周期存储文件。静态租约表中的IP地址不能重复使用。

![dhcp_message_format](img/dhcp_message_format.png)

​		DHCP属于**引导程序协议**，DHCP报文格式符合BOOTP报文格式。

| 字段   | 长度(字节) | 含义                                                         |
| ------ | ---------- | ------------------------------------------------------------ |
| op     | 1          | 报文类型，1表请求报文，2表示响应报文                         |
| htype  | 1          | 客户端硬件地址类型，1表示以太网地址                          |
| hlen   | 1          | 客户端硬件地址长度                                           |
| hops   | 1          | 跳数，客户端置0                                              |
| xid    | 4          | 报文的唯一值                                                 |
| secs   | 2          | 客户端获取到IP地址或续约成功到现在所消耗的时间，若未获得IP地址则为0 |
| flags  | 2          | DHCP仅用到了第一位，0表示单播的方式，1表示广播的方式，其余位保留 |
| ciaddr | 4          | 客户端IP地址                                                 |
| yiaddr | 4          | 服务器分配给客户端的IP地址                                   |
| siaddr | 4          | 服务器IP地址                                                 |
| giaddr | 4          | 网关IP地址                                                   |
| chaddr | 16         | 客户端硬件地址                                               |
| sname  | 64         | 服务器主机名，全为0则表示没有                                |
| file   | 128        | 引导文件名，全为0则表示没有                                  |
| vender | 可变       | 采用CLV模式，对于DHCP，必须以固定值01100011 10000010 01010011 01100011开头，表示Magic cookie，即之后是vender |

​		DHCP有8种报文，根据`Optiont(53)`可以区分，即**DHCP发现报文**、**DHCP提供报文**、**DHCP请求报文**、**DHCP ACK报文**、**DHCP NAK报文**、**DHCP拒绝报文**、**DHCP释放报文**和**DHCP信息报文**。

![dhcp_client_server_interaction](img/dhcp_client_server_interaction.png)

​		1）DHCP服务器发现。新到达的DHCP客户端首先需要寻找DHCP服务器。DHCP客户端以广播的方式发送DHCP发现报文，报文段封装成数据报时源IP地址是`0.0.0.0`，目的IP地址使用广播地址。

​		2）DHCP服务器提供。所有收到DHCP发现报文的DHCP服务器发送包括发现报文的事务ID、推荐IP地址、子网掩码以及IP**地址租用期**的DHCP提供报文来响应，报文段封装成数据报时目的IP地址使用广播地址，因为子网中可能存在多个新到达的DHCP客户端。若为静态租用则匹配硬件地址，若为动态租约则检测DHCP发现报文中是否包含有效`yiaddr`，有则进一步检测是否可用，否则从IP地址池中分配一个最小可用的IP地址。

​		3）DHCP请求。DHCP客户端可能会收到多个DHCP提供报文，DHCP客户端选择一个并发送包含配置参数的DHCP请求报文来响应。报文段封装成数据报时源IP地址是`0.0.0.0`，目的IP地址使用广播地址。

​		4）DHCP ACK/NAK。DHCP服务器根据客户端的状态进行响应，若客户端处于`selecting`则验证`yiaddr`和`siaddr`是否匹配，若客户端处于`init_reboot`则验证`yiaddr`是否匹配，若客户端处于`renewing/rebinding`则验证`ciaddr`是否匹配，若都不匹配以单播的方式发送DHCP NAK报文，反之则发送DHCP ACK报文。

​		﹡当客户端的IP地址租期到$\frac{1}{2}$，客户端会以单播的方式向原服务器发送DHCP请求报文，若收到DHCP ACK报文则续租成功并更新租期，最多可重发3次，分别在4s、8s和16s后。

​		﹡当客户端的IP地址租期到$\frac{7}{8}$，客户端会以广播的方式向所有服务器发送DHCP请求报文，若收到DHCP ACK报文则更新租约，最多可重发3次，分别在4s、8s和16s后。

​		租约到期则重新开始【发现-提供-请求-确认】这4个步骤。

​		若客户端收到DHCP ACK报文后，向网络发送3个此IP地址的ARP解析请求以执行冲突检测。若出现冲突，客户端向服务器发送DHCP拒绝报文来重新获取IP地址，服务器会将租约表中关于客户端硬件地址置空并保持该IP地址一段时间。若客户端==不再需要当前IP地址或租约到期==，向服务器发送DHCP释放报文。若客户端需要获取租约的详细信息，可以向服务器发送DHCP信息报文，服务器会以DHCP ACK报文响应。

##### 4.2.4 IPv6

![ipv6_datagram_format](img/ipv6_datagram_format.png)

​		IPv6数据报包括8位的**版本(号)**、8位的**流量类别**、16位的**流标签**、16位的**有效载荷长度**、8位的**下个首部**、8位的**跳限制**、128位的**源IP地址**、128位的**目的IP地址**、非必需且长度不定的扩展首部以及有效载荷。

​		流量类别等同于IPv4数据报中的服务类型。

​		类标签用于区分实时流量，不同的流标签+源IP地址可以确定唯一的数据流。

​		有效载荷长度包括==扩展首部的长度+有效载荷的长度==，若超过65535则使用扩展首部中的超大有效载荷来表示。

​		下个首部类似于IPv4数据报中的上层协议，若存在下一个扩展首部则表示下一个扩展首部的编号，反之则表示传输层协议的编号。

| 扩展首部类型             | 对应的下个首部值 | 描述                                                         |
| ------------------------ | ---------------- | ------------------------------------------------------------ |
| 逐跳选项扩展首部         | 0                | 用于为在传输链路上每跳转发指定参数，传输链路的每台中间节点都要读取并处理该字段。主要应用包括超大有效载荷、设备提示以及资源预留 |
| 路由选择扩展首部         | 43               | 用于强制让数据报经过特定的设备                               |
| 分片扩展首部             | 44               | 用于分片                                                     |
| 封装安全有效载荷扩展首部 | 50               | 由IPsec使用，提供认证、数据完整性校验以及重放保护，类似于认证 |
| 认证扩展首部             | 51               | 由IPsec使用，提供认证、数据完整性校验、首部部分字段保护以及重放保护 |
| 目的选项扩展首部         | 60               | 携带只有目的主机才会处理的信息                               |

​		跳限制等同于IPv4数据报中的生存时间。

​		IPv6数据报必须按照指定顺序：首部、逐跳选项首部扩展首部、目的选项扩展首部、路由选择扩展首部、分片扩展首部、认证扩展首部、封装安全有效载荷扩展首部、目的选项扩展首部以及有效载荷。

​		IPv6==只允许源主机和目的主机==进行分片与重组。若路由器收到的数据报因太大无法转发到链路上，则路由器丢弃该数据报并向发送端发送一个ICMP差错报文，然后发送端以较小长度的数据报重发。

​		由于传输层和链路层的协议都有差错检测，故IPv6并没有校验和。

![tunneling](img/tunneling.png)

​		IPv4迁移到IPv6的方法是**建立隧道**。其基本思想是：假设两个IPv6主机需要使用IPv6数据报进行交互，但它们的传输路径经过IPv4路由器，将路径上的IPv4路由器集合为一个**隧道**，借助隧道，将IPv6数据报作为IPv4数据报的有效载荷。

#### 4.3 路由选择算法

​		无向图$G=(N,E)$是一个$N$个节点和$E$条边的集合，其中每条边是取$N$的一对节点。节点可以表示路由器，连接节点的边可以表示路由器之间的物理路径。对于$E$中的任意一条边$(x,y)$，$c(x,y)$表示节点$x$和$y$的成本。若节点对$(x,y)$不属于$E$，则$c(x,y)=\infty$，反之则两个节点互称**邻居**。$u$表示源节点。

​		对于任何两个节点$x$和$y$，通常有很多条路径，这些路径中的一条或多条是**最低成本路径**。当所有边的成本相同时，最低成本路径就是**最短路径**。

​		节点$x$到节点$y$的最低成本可以用Bellman-Ford算法表示，即$d_{x}(y)=min_{v}\{c(x,v)+d_{v}(y)\}$，其中$v$表示$x$的所有邻居。

​		路由选择算法根据集中式/分布式可以分为**集中式路由选择算法**和**分布式路由选择算法**，根据静态/动态可以分为**静态路由选择算法**和**动态路由选择算法**，根据负载的敏感可以分为**负载敏感算法**和**负载迟钝算法**。

​		﹡集中式路由选择算法以网络拓扑以及所有链路的成本为输入。具有全局状态信息的算法称为**链路状态算法**。

​		﹡分布式路由选择算法中，每个节点开始时仅有与其直连链路的成本信息，然后通过迭代计算过程以及与相邻节点交换信息，逐渐计算出到达某个或某组目的节点的最低成本路径。每个节点维护到其他节点的成本(距离)估计的向量称为**距离向量算法**，主要通过与相邻路由器间交换交互式报文。

​		﹡静态路由选择算法中路由选择随时间的变化非常缓慢，通常是人工进行调整。

​		﹡动态路由选择算法随着网络流量负载或拓扑变化而改变路由选择路径。一个动态路由选择算法可以周期性地或直接响应拓扑以及链路成本变化。

​		﹡负载敏感算法中，链路成本会动态地变化来反映底层链路的当前拥塞水平。若当前拥塞的链路与高成本相关联则该算法会趋向绕开该拥塞链路来选择路由。

​		﹡负载迟钝算法中，链路成本不会明确地反映其当前会最近的拥塞水平。

​		**收敛**指网络中所有路由器的路由选择表中的信息完全一致。

##### 4.3.1 LS算法

​		链路状态算法通过让每个节点向网络中所有其他节点广播链路状态分组来获得网络拓扑以及所有链路成本，其中每个链路状态分组包含它所连接的链路的标识和成本，这通常由**链路状态广播算法**来完成。

​		Dijkstra算法从某节点到网络中所有其他节点的最低成本路径，该算法是迭代算法，迭代$k$次后可以获得$k$个目的节点的最低成本路径。$D(v)$表示到本次迭代为止，从源节点$u$到节点$v$的最低成本路径的成本。$p(v)$表示源节点$u$到节点$v$的当前最低成本路径中$v$的前一节点。$N'$表示节点子集，若源节点$u$到节点$v$的最低成本路径已知，则$N'$包含$v$。

```assembly
;初始化阶段：N'仅包含u，若v是u的邻居则D(v)=c(u,v)，p(v)=u，反之则D(v)=∞。
Initialization:
	N' = {u}
	for all nodes v
		if v is a neighbor of u
			D(v) = c(u, v)
			p(v) = u
		else D(v) = ∞
;循环阶段：查找不在N'中且到u的最短成本路径最小的节点w，将w加入N‘。若节点v不在N'中且是w的邻居则更新D(v)和p(v)。当N'包含所有节点时结束循环。
Loop
	find w not in N' such that D(w) is a minimum
	add w to N'
	update D(v) for each neighbor v of w and not in N':
		if D(v) > D(w) + c(w, v)
			p(v) = w
			D(v) = D(w) + c(w, v)
until N' = N
```

![link_state_algorithm_in_operation](img/link_state_algorithm_in_operation.png)

​		LS算法结束后，获得了除源节点以外的每个节点的最低成本路径以及前一节点。

![osciallations_with_congestion_sensitive_routing](img/osciallations_with_congestion_sensitive_routing.png)

​		当出现振荡时，最简单的解决方法是强制链路成本与承载的流量无关，但是这违背了路由选择的初衷之一——避开拥塞严重的链路。另一种解决方法是确保并非所有的路由器都同时运行LS算法。路由器最初在同一周期的不同时间执行算法，但最终算法会在路由器上同步并一直保持。避免这种自同步的方法之一就是让每台路由器发送链路通告的时间随机化。

##### 4.3.2 DV算法

​		根据Bellman-Ford算法可以实现邻居间的通信，基本思想是对应每个节点$x$以$D_x(y)$开始，对于$N$中的所有节点$y$，估计从$x$到$y$的最低成本路径的成本。$D_x=[D_x(y):y\in N]$表示节点$x$的距离向量，该向量是从$x$到$N$中所有目的地节点$y$的成本估计向量。

​		使用DV算法，每个节点$x$需要维护自身的距离向量$D_x=[D_x(y):y\in N]$，每个邻居$v$的成本$c(x,v)$以及每个邻居$v$的距离向量$D_v=[D_v(y):y\in N]$。每个节点不时地向每个邻居发送它的距离向量副本，邻居收到新的距离向量时，保存该距离向量并使用Bellman-Ford算法更新自身的距离向量。当节点的距离向量因收到邻居的距离向量或链路成本变化而改变时，该节点需要向所有邻居发送改变后的距离向量。

```assembly
Initialization:
	for all destinations y in N:
		Dₓ(y) = c(x,y)
	for each neighbor v
		Dᵥ(y) = ? for all destinations y in N
	for each neighbor v
		send distance vector Dₓ = [Dₓ(y):y in N] to v
Loop
	wait until link cost changes or receive a distance vector
	for each y in N:
		Dₓ(y) = minᵥ{c(x,y) + Dᵥ(y)}
	if Dₓ(y) changed for any destination y
		send distance vector Dₓ = [Dₓ(y):y in N] to all neighbors
forever
```

![distance_vector_algorithm_in_operation](img/distance_vector_algorithm_in_operation.png)

​		假设$t_0$时刻$x$与$y$间的链路成本从2增加到10，则$D_y(x)=min\{10+0,1+3\}=4$，若$y$需要发送分组到$x$，则需要通过$z$，$t_1$时刻分组到达$z$，但是$z$节点的路由选择表中是通过$y$到达$x$，然后就出现了**路线选择环路**，即从$y$发往$x$的分组在$y$和$z$间来回传输。在$t_1$后的某个时刻，$z$收到了$y$的新距离向量，即$D_y(x)=4$，重新计算到$x$的最低成本$D_z(x)=min\{7+0,1+4\}=5$，$t_2$时刻$y$收到$z$的新距离向量，即$D_z(x)=5$，重新计算到x的最低成本$D_y(x)=min\{10+0,1+5\}=6$，这个过程会一直持续到$D_z(y)=11$，然后$z$确定到$x$的最低成本路径就是直接到$x$而不是通过$y$。当$c(x,y)$从4变为10000时，这种情况可以成为**无穷计数**问题。

​		通过**毒性逆转**可以解决这种==仅涉及2个节点==的简单路由选择环路，若$z$需通过$y$到达$x$，则发送$D_z(x)=\infty$的新距离向量给$y$来毒化$z$到$y$的逆向路径。$y$会发送$D_y(x)=10$的新距离向量给$z$，因为$y$不再通过$z$到$x$，之后$z$发送$D_z(x)=7$的新距离向量给$y$，$y$更新到$x$的最低成本路径的成本$D_y(x)=8$，此时$z$位于$y$到$x$的最低成本路径上，$y$发送$D_y(x)$的新距离向量来毒化$y$到$z$的逆向路径。

##### 4.3.3 LS算法与DV算法的比较

​		在LS算法的具体实现中，每个节点需要将该节点到所有邻居的直接相连链路的成本广播到其他所有节点。而在DV算法的具体实现中，每个节点仅需将已知的该节点到其他节点的估计最低成本发送给所有邻居。

​		﹡从报文复杂性的角度，LS算法需要发送$O(|N||E|)$个报文，当某条链路的成本改变时需要重新向其他节点发送报文；DV算法需要迭代的过程中仅邻居间交换报文，当某个节点到另一节点的最低成本路径的成本改变时才发送改变后的路径成本。

​		﹡从收敛速度的角度，LS算法的收敛所需时间为$O(|N|^2)$；DV算法的收敛速度较慢，收敛的过程中可能会出现路由选择环路以及无穷计数。

​		﹡从健壮性的角度，LS算法使用了广播的形式，每个节点仅计算自身的路由选择表，即每个节点在一定程度上是分离的，若某个节点损坏或丢弃了某个收到的分组也只会影响自身的路由选择表，保证了一定的健壮性；DV算法中每次迭代中每个节点的计算的最低成本路径的成本会发送给邻居，在下次迭代中会进一步扩散，经过一段时间，一个错误的最低成本路径的成本会扩散到整个网络。

#### 4.4 OSPF

​		OSPF是一种链路状态协议，它使用链路状态信息泛洪和Dijkstra最低成本路径算法。**链路状态通告**包含在OSPF报文中，OSPF报文由==直接由IP承载==。每台路由器都构建了整个AS的完整拓扑图，然后每台路由器在本地运行Dijkstra最低成本路径算法，以确定以自身为根节点到所有子网的最短路径树。OSPF不强制设置路径权值，而是提供一种协议，为给定链路权值集合确定最低成本路径的路由选择。

​		OSPF协议中，当一条链路的状态发生变化时，路由器会广播链路状态信息，即使未发生变化，路由器也周期性地广播链路状态信息。OSPF协议需要检测链路是否正常运行(通过邻居间发送HELLO报文)，允许路由器获得邻居网络范围内链路状态的数据库。

​		OSPF的优点包括安全、多条相同成本的路径、对单播与多播路由选择的综合支持以及支持单个AS中的层次结构。

​		﹡OSPF协议提供了报文的认证来保证安全性。OSPF报文默认不启用认证，可以配置简单认证和MD5认证。简单验证基于配置在所有路由器中的共享密码，但密码会以明文的形式出现在OSPF报文中。MD5认证基于配置在所有路由器上的共享密钥，发送路由器在OSPF报文中加入报文内容加密钥的MD5散列值。MD5认证与序号一起使用来防止重放攻击。

​		﹡当存在多条成本相等的路径时，无须仅选择单一的路径来承载所有的流量。

​		﹡MOSPF是OSPF的简单扩展，用来提供多播的支持。

​		﹡一个OSPF自治系统可以分层并配置为区域，其中只能存在一个主干区域，每个区域都运行自身的LS算法。在每个区域内，一台或多台区域边界路由器负责为发往区域外的分组提供路由选择。主干区域包含所有的区域边界路由器，可能包含一些非边界路由器。分组在区域间的路由选择需要先区域内路由到一个区域边界路由器，再通过主干区域路由到目的区域的区域边界路由器，最后路由到目的地。

#### 4.5 BGP

##### 4.5.1 BGP

​		在BGP中，分组并不是路由到一个特定的目的IP地址，而是路由到类似于CIDR的前缀，该前缀表示一个子网或一个子网的集合。因此，路由器的转发表将具有$(x,I)$形式的表项，$x$表示例如138.116.68/22的前缀，$I$表示该路由器的某个接口的接口号。

​		BGP允许每个子网向因特网的其他部分通告它的存在，同时确保所有AS收到该通告。

​		一台路由器可能知道多条到指定前缀的不同路由，为了确定最好的路由，而最好的路由基于策略以及可达性信息来确定，该路由器将在本地运行BGP路由选择(类似于DV算法，通过邻居获得前缀的可达性信息)。

![ebgp_and_ibgp_connections](img/ebgp_and_ibgp_connections.png)

​		在BGP中，每条直接连接以及所有通过该连接发送的报文称为**BGP连接**。若BGP连接跨越AS则称为**外部BGP**连接，若在同一AS则称为**内部BGP**连接。内部BGP连接==并不总是==对应物理链路。建立BGP连接的两个路由器互称**BGP对等体**，其中发送BGP报文的路由器称为**BGP发言者**。

​		对于每个AS，其中的路由器是要么是**网关路由器**，要么是**内部路由器**。网关路由器位于AS边缘，内部路由器仅连接AS内部的主机和路由器。

​		若需要通告前缀$x$的可达性信息，对于跳数较多的路径，首先网关路由器3a向网关路由器2c发送EBGP报文“AS3 $x$”，然后网关路由器2c向AS2内的所有其他路由器发送IBGP报文“AS3 $x$”，最后网关路由器2a向网关路由器1c发送EBGP报文"AS2 AS3 $x$"。

​		路由器通过BGP连接通告前缀时，前缀中包括一些**BGP属性**，前缀以及属性称为**路由**。BGP属性分为**公认必遵**、**公认任意**、**可选传递**和**可选非传递**。

| BGP属性类别 | BGP属性类别详情                                              | 包含的BGP属性                              |
| ----------- | ------------------------------------------------------------ | ------------------------------------------ |
| 公认必遵    | 所有BGP路由器必须支持，必须包含于更新报文中                  | ORIGIN、AS_PATH、NEXT_HOP                  |
| 公认任意    | 所有BGP路由器必须支持                                        | LOCAL_PREF、ATOMIC_AGGREGATE               |
| 可选传递    | 可以不支持，即使不支持也应该能接收包含该属性的路由并传递给邻居 | COMMUNITY、AGGREGATOR                      |
| 可选非传递  | 可以不支持，若不支持则可以忽略包含该属性的更新报文           | MULTI_EXIT_DISC、ORIGINATOR_ID、CLUSTER_ID |

​		**ORIGIN**标识路由信息的来源。

​		**AS_PATH**包含了通告已通过的AS列表，可用来检测和防止通告环路，若路由器在AS_PATH中发现包含了自身所属的AS则拒绝该通告。

​		**NEXT_HOP**是==AS_PATH起始路由器接口的IP地址==。对于从AS1通过AS2到$x$的路由"AS2 AS3 $x$"，NEXT_HOP是路由器2a的左边接口的IP地址。对于AS1直接路由到AS3的路由"AS3 $x$"，NEXT_HOP是路由器3d的最左边接口的IP地址。

​		**LOCAL_PREF**表示路由的优先级，仅用在IBGP对等体间，由==本地AS的路由选择策略==决定。

​		**ATOMIC_AGGREGATE**表示路由是经过了聚合。

​		**COMMUNITY**表示共享相同属性的目的地集合，用于将路由信息编组，通过组的标识决定路由策略的传递。

​		**AGGREGATOR**是ATOMIC_AGGREGATE的补充，包含发起路由聚合的ASN和形成聚合路由的BGP发言者的IP地址。

​		**MULTI_EXIT_DISC**用于区分同一相邻AS的多个接口。

​		**ORIGINATOR_ID**用于标识路由反射器。

​		**CLUSTER_ID**用于标识路由反射器组。

##### 4.5.2 BGP路由选择

​		**热土豆路由选择**可以从所有可能的路由中选择到对应NEXT_HOP路由器成本最小的路由，忽略剩余端到端成本。

​		使用热土豆路由选择在转发表中增加AS外部目的前缀的步骤如下：

​		①从AS间路由选择协议知道可通过多个网关到达子网$x$。

​		②通过AS内部路由选择协议获取的路由选择信息来计算到每个网关的最低成本路径的成本。

​		③根据热土豆路由选择来选择成本最低的网关。

​		④从转发表确定通往最低成本网关的接口$I$并在转发表中加入表项$(x,I)$。

​		BGP实际使用的路由选择算法结合了热土豆路由选择的特点但更复杂。对应给定的目的前缀，算法的输入是到路由器已知悉且接受的到该前缀的所有路由的集合。若集合中多个路由则按下列消除原则直至最后一条路由：

​		1）路由被分配LOCAL_PREF作为BGP属性之一。路由的LOCAL_PREF可能已由路由器设置，也可能已从同一AS中的另一台路由器获悉。选择具有最高LOCAL_PREF的路由。

​		2）选择具有最短AS_PATH的路由。若该规则是路由选择的唯一规则，则BGP将使用DV算法决定路径，其中距离测量使用AS跳的跳数而不是路由器跳的跳数。

​		3）使用热土豆路由选择，选择到NEXT_HOP路由器成本最小的路由。

​		4）使用BGP标识符来选择路由。

![simple_policy_scenario](img/simple_policy_scenario.png)

​		假设A、B、C是主干提供商网络，且A、B、C直接向彼此发送流量，并向它们的客户网络提供全部的BGP信息，则W、Y是接入ISP，X是**多宿接入ISP**。可以通过控制BGP路由的通告的方式保证W、X和Y的存根网络行为，例如X可能知道到Y的一条路径(XCY)，但X==不会==将此路径通告给B，因此B也不会经由X来转发到C或Y的分组。

​		所有进入接入ISP网络的流量必定是以该网络为目的地，所有离开接入ISP网络的流量必定源自该网络。

​		各个对等协议通常都是ISP双方协商且通常对外保密。

​		商业规则是任何流经ISP提供商网络的流量的源或目的地(或两者)必须位于该ISP的客户网络中，反之则这些流量将免费通过该ISP的网络。

##### 4.5.3 IP任播

​		当BGP被用于实现IP任播时，常用于DNS中。

![ip_anycast_forwards_requests_to_the_closest_cdn_server](img/ip_anycast_forwards_requests_to_the_closest_cdn_server.png)

​		在IP任播配置时，CDN公式为多台CDN服务器指派了==相同的IP地址==，然后这些服务器中的每一台都使用BGP来通告该IP地址。当某台BGP路由器该IP地址的多路由通告时，它将这些通告视为到同一物理位置的不同路径，配置路由选择表时，路由器将在本地使用BGP路由选择算法来确定最合适的路由。实际中CDN通常不使用IP任播，因为BGP路由选择的变化可能导致同一的TCP连接的的分组到达Web服务器的不同实例。

​		在DNS系统中，IP任播常用于将DNS请求指向最近的根DNS服务器。

#### 4.6 SDN

​		SDN体系结构包括**基于流的转发**、**数据平面和控制平面分离**、**网络控制**以及**可编程网络**这4个关键特征。

![sdn_architecture](img/sdn_architecture.png)

​		控制平面由SDN控制器(或网络操作系统)以及若干网络控制应用程序(运行在网络控制服务器上)组成。控制器维护准确的网络状态信息并为网络控制应用程序提供这些信息，还为这些应用程序提供方法来监控、编程以及控制底层网络设备。

​		SDN控制器的功能可分为**通信层**、**网络范围状态管理层**和**网络控制应用层的接口**。

​		﹡若SDN控制器需要控制远程设备，则需要一个协议(OpenFlow)来为SDN控制器和该设备传输信息。此外，该设备必须能够将本地观察到达的事件传输给SDN控制器。SDN控制器和受控网络设备之间的通信跨越了SDN控制器所谓的“南向”接口。

​		﹡SDN控制平面做出的最终控制决策将要求SDN控制器具有网络主机、链路、交换机和其他SDN控制的设备的最新状态信息。交换机的流表包含计数器，其值可以为网络控制应用程序所用。因为控制平面的最终目标是确定各种受控设备的流表，SDN控制器可能也维护这些表的副本。

​		﹡SDN控制器通过它的“北向”接口与网络控制应用程序交互。该接口允许网络控制应用程序在状态管理层中读取/写入网络状态和流表。应用程序可以注册以状态更新事件时收到通知，这样它们可以采取行动以响应来自受控于SDN的设备发送的网络事件通知。

##### 4.6.1 OpenFlow

​		==OpenFlow==是一个得到高度认可和成功的标准，它开创了匹配加动作转发抽象、控制器的概念以及更广泛的SDN革命。实际应用包括简单转发、负载均衡以及防火墙。

​		匹配加动作转发表在OpenFlow中称为**流表**。表项包括首部字段值的集合、计数器集合以及匹配项对应的动作集合。当匹配成功时更新计数器，计数器可能包括匹配成功分组的数量以及上次更新时间。匹配失败的分组将被丢弃或发送到远程控制器进行更多处理。在实践中，一个流表可能由多个流表实现。动作包括转发给指定的一个或多个输出端口、丢弃、复制以及重写部分首部字段。

![packet_matching_fields_of_openflow_1.0_flow_table](img/packet_matching_fields_of_openflow_1.0_flow_table.png)

​		支持OpenFlow的设备可以充当路由器转发分组以及充当交换机转发帧。以太网类型对应用来分解复用帧的有效载荷的传输层协议。

​		输入端口指路由器接收分组的输入端口。

​		流表项可以使用通配符`*`。每个流表项具有优先级。

​		动作中重要的动作包括转发、丢弃和修改字段。

​		﹡分组可以转发到指定的物理输出端口，可以广播到所有端口，也可以通过所选的端口集合进行多播。该分组可能被封装并发送到远程控制器，远程控制器可能会对分组进行某些动作，例如安装新的流表项并可能返回分组来更新流表项来根据更新的流表项转发。

​		﹡没有对应动作时分组将被丢弃。

​		﹡分组被转发到指定的输出端口之前，源MAC地址、目的MAC地址、以太网类型、局域网ID、局域网优先级、源IP地址、目的IP地址、服务类型、源端口、目的端口这些字段的值可以重写。

​		从SDN控制器流向受控路由器的重要报文包括==配置==报文、==修改状态==报文、==读取状态==报文、==发送分组==报文。配置报文允许SDN控制器查询并设置路由器的配置参数。修改状态报文用于增加/删除/修改路由器流表中的表项并设置路由器的端口属性。读取状态报文用于从路由器的流表和端口收集统计数据以及计数器值。发送分组报文用于从受控路由器的指定端口发送特定报文，报文的有效载荷包含分组。

​		从受控路由器流向SDN控制器的重要报文包括==流删除==报文、==端口状态==报文、==分组进入==报文。流删除报文用于通知SDN控制器已删除一个流表项。端口状态报文用于向SDN控制器通知端口状态的变化。分组进入报文用于分组匹配成功的分组发给SDN控制器。

##### 4.6.2 数据平面与控制平面的交互

![sdn_scenario_link_state_change](img/sdn_scenario_link_state_change.png)

​		Dijkstra算法是实现在每台路由器中泛洪链路状态更新，这里Dijkstra算法作为路由器外部的一个单独的程序而且路由器将链路更新发送到SDN控制器而不是彼此。

​		假设OpenFlow作为通信层协议，控制平面只执行路由选择。此外，s1与s2之间的链路出现了故障。

​		1）s1使用OpenFlow的端口状态报文通知SDN控制器链路状态改变。

​		2）SDN控制器收到报文后通知链路状态管理器，链路状态管理器更新链路状态数据库。

​		3）因为用于实现Dijkstra算法的网络控制应用程序之前已经注册，网络控制应用程序收到了链路状态更改的通知。

​		4）链路状态应用程序与链路状态管理器交互以获取最新的链路状态信息，也可能会与链路状态管理层的其他组件交互，然后计算新的最低成本路径。

​		5）链路状态应用程序与流表管理器交互来更新流量。

​		6）流表管理器使用OpenFlow更新受影响路由器的流表项。

##### 4.6.3 SDN的发展

​		Google的B4网络使用定制的交换机，每台交换机实现了OpenFlow的扩展版并带有本地OpenFlow代理。每个OFA与网络控制服务器中的OpenFlow控制器连接，使用单独的“带外”网络，该网络不同于数据中心间传输数据中心流量的网络。OpenFlow控制器因此提供网络控制服务器和其受控交换机之间的通信。在B4中，OpenFlow控制器还执行状态管理功能，将节点与链路信息保存在网络信息数据库中。OpenFlow控制器的实现基于ONIX SDN控制器。B4网络实现了BGP和IS-IS(类似于OSPF)。

​		在SDN发展早期，采用单一的SDN协议(OpenFlow)和单一的SDN控制器。最近，OpenDaylight(ODL)控制器和ONOS控制器得到业界广泛支持。

![opendaylight_simplified_architecture](img/opendaylight_simplified_architecture.png)

​		**网络服务应用程序**用于决定受控路由器完成数据平面转发和其他服务(如防火墙和负载均衡)。ODL控制器的核心是**基本网络服务功能**。控制器有RESTful接口和网络抽象层这2个接口，外部应用程序通过HTTP上的RESTful接口与控制器通信，内部应用程序通过SAL相互通信。应用程序实现在控制器外部还是控制器内部由应用程序设计者决定。

​		SAL允许控制器组件和应用程序互相调用并订阅彼此生成的事件，它还为通信层中特定的协议(如OpenFlow、SNMP和OVSDB)提供统一的抽象接口。

![onos_simplified_architecture](img/onos_simplified_architecture.png)

​		ONOS作为服务部署在一组互联的服务器上，每台服务器都运行相同的ONOS软件副本。

​		ONOS的一个独特功能是它的意图框架，它允许网络控制应用程序请求高级服务而无须了解该服务的具体信息。状态信息通过北向接口以同步(查询)或异步(监听器回调)提供给应用程序。

​		ONOS的分布式核心维护网络链路、主机以及设备的状态等。ONOS核心提供复制和实例间协调机制，为上层的应用程序和下层的受控设备提供逻辑上的集中式核心服务抽象。

​		ONOS的南向接口屏蔽底层主机、链路、交换机和协议的差异，允许分布式核心和这些无关。

#### 4.7 ICMP

​		ICMP虽然是网络层协议，但ICMP报文作为IP数据包的有效载荷，类似于TCP和UDP。ICMP最典型的用途是差错报告。基于ICMP的常用程序是ping和traceroute。

![icmp_message_format](img/icmp_message_format.png)

| ICMP type | ICMP code | 描述                              |
| --------- | --------- | --------------------------------- |
| 0         | 0         | echo(ping) reply                  |
| 3         | 0         | destination network unreachable   |
| 3         | 1         | destination host unreachable      |
| 3         | 2         | destination protocol unreachable  |
| 3         | 3         | destination port unreachable      |
| 3         | 6         | destination network unknown       |
| 3         | 7         | destination host unknown          |
| 4         | 0         | source quench(congestion control) |
| 8         | 0         | echo(ping) request                |
| 9         | 0         | router advertisement              |
| 10        | 0         | router discovery                  |
| 11        | 0         | TTL exceeded                      |
| 12        | 0         | IP header bad                     |

​		源抑制报文最初的目的是用于拥塞控制，即发送或对方减小发送速率。

​		在traceroute中，为了确定源主机和目的主机之间的路由器的主机板和IP地址，源主机向目的主机发送了一系列的IP数据报，这些数据报都带有一个不可达的UDP端口的UDP报文段，其中第$n$个数据报的TTL为$n$。因此，当第$n$个数据报到达第$n$个路由器时TTL刚好过期，路由器丢弃数据报并向源主机发送ICMP报文(type=11,code=0)，该报文包括路由器的主机名以及IP地址。当数据报到达目的主机时，由于UDP端口不可达，目的主机会向源主机发送ICMP报文(type=3,code=3)，源主机收到该报文后停止发送数据报。

#### 4.8 网络管理

##### 4.8.1 网络管理

​		**网络管理**包括对硬件、软件和人为元素的部署、集成和协调，以便对网络资源进行监视、测试、轮询、配置、分析、评估和控制，这样能以合理的成本满足例如实时运行性能、服务质量等需求。

![components_of_network_management](img/components_of_network_management.png)

​		网络管理的重要组件包括管理服务器、被管设备、MIB数据、远程代理以及SNMP。

​		管理服务器是一个应用程序，通常有人的参与，并在网络运营中心的集中式管理站上运行。管理服务器用于网络管理，负责网络管理信息的收集、处理、分析以及显示。

​		被管设备是被管网络中的网络设备(包括软件)。一个被管设备内可能有几个**被管对象**。这些被管对象包括被管设备中的实际硬件(例如网络接口卡是主机或路由器的一个组件)以及用于这些硬件和软件组件的配置参数(例如AS内部路由选择协议)。

​		被管设备中的每个被管对象的相关信息收集在**管理信息库**中，这些信息可供管理服务器使用。一个管理信息库的对象称为SMI，可以是计数器、收到的UDP报文的数量、描述性信息或状态信息等。

​		每个被管设备上都有**网络管理代理**，它是一个与管理服务器通信的进程，在管理服务器的命令和控制下在被管设备执行本地操作。

​		**网络管理协议**在管理服务器与被管设备间运行，运行管理服务器查询被管设备的状态并通过代理间接地在被管设备上采取行动。代理通过网络管理协议通知管理服务器异常事件。

##### 4.8.2 SNMP

​		**简单网络管理协议**用于管理服务器和被管设备上的网络管理代理之间传输网络管理控制和信息报文。SNMP常用模式是请求响应模式，管理服务器向代理发送请求，代理收到请求后执行某些操作并响应请求。请求通常用于查询或修改被管设备相关的MIB对象值。另一种情况是代理向管理服务器发送未被请求的报文，该报文称为**陷阱报文**。陷阱报文是异步产生的，即不是为了响应报文，而是为了响应管理服务器要求通知的事件，用于通知管理服务器异常情况导致MIB对象值改变。

| PDU类型        | 发送端-接收端                           | 描述                                                         |
| -------------- | --------------------------------------- | ------------------------------------------------------------ |
| GetRequest     | 管理服务器到代理                        | 获取一个或多个MIB对象值                                      |
| GetNextRequest | 管理服务器到代理                        | 获取下一个MIB对象值                                          |
| GetBulkRequest | 管理服务器到代理                        | 获取大数据块的值                                             |
| InformRequest  | 管理服务器到管理服务器                  | 通知==远程==管理服务器远程访问的MIB值                        |
| SetRequest     | 管理服务器到代理                        | 设置一个或多个MIB对象值                                      |
| Response       | 代理到管理服务器/管理服务器到管理服务器 | 响应GetRequest、GetNextRequest、GetBulkRequest、InformRequest和SetRequest |
| Trap           | 代理到管理服务器                        | 通知管理服务器异常事件                                       |

![snmp_pdu_format](img/snmp_pdu_format.png)

​		SNMP通常基于UDP，但UDP并不可靠，类似于rdt，管理服务器用Request Id来标识报文。SNMP并没有强制重传，若需要重传，管理服务器设置重传频率和周期。

​		GetRequest、GetNextRequest、GetBulkRequest PDU请求的值在PDU的变量绑定部分。GetRequest、GetNextRequest、GetBulkRequest PDU的数据请求颗粒度不同， GetRequest可以请求任意一组MIB值，多个GetNextRequest可用于对MIB对象的列表或表格进行排序，GetBulkRequest用于返回大块数据，相比多个GetRequest或GetNextRequest减小了成本。代理会使用包含对象标识符以及相关值的PDU来响应。

​		代理用带有"noError"错误状态的PDU来响应SetRequest。

### 第五章 链路层

​		运行链路层协议的设备称为**节点**。连接相邻节点的通信信道称为**链路**。

​		链路层提供的服务包括封装成帧、链路接入、可靠交付、差错检测和纠正。

![relationship_of_network_adapter_to_other_host_components](img/relationship_of_network_adapter_to_other_host_components.png)

​		通常链路层是通过**网络适配器**实现的，网络适配器也成为**网络接口卡**。网络适配器的核心是链路层控制器，通常是一个实现了很多链路层服务的专用芯片。因此，链路层控制器的大部分功能(封装成帧、链路接入和差错检测)是通过硬件实现的。链路层的软件部分实现更高级别的链路层功能(组装链路层寻找信息和激活控制器硬件)。

#### 6.1 差错检测和纠正

### 附录1 专业术语

> **access point(AP)** 访问接入点
>
> **acknowledgment(ACK)** 确认
>
> **active optical network terminator(AON)** 主动光纤网络
>
> **active queue management(AQM)** 主动队列算法
>
> **additive increase,multiplicative decrease(AIMD)** 加性增、乘性减
>
> **address aggregation** 地址聚合
>
> **address lease time** 地址租用期
>
> **aggregator** 聚合器
>
> **alternating bit protocol** 比特交替协议
>
> **anycast** 任播
>
> **application programming interface(API)** 应用程序编程接口
>
> **asynchronous transfer mode(ATM)** 异步传输模式
>
> **atomic aggregate** 原子聚合
>
> **automatic repeat request(ARQ)** 自动重传请求
>
> **autonomous system(AS)** 自治系统
>
> **available bite rate(ABR)** 可用比特率
>
> **average throughput** 平均吞吐量
>
> **band width** 带宽
>
> **bandwidth sensitive application** 带宽敏感的应用
>
> **Berkeley Internet Name Domain(BIND/NAMED)** DNS服务器软件
>
> **best effort delivery service** 尽力而为交付服务
>
> **best effort service** 尽力而为服务
>
> **BGP attribute** BGP属性
>
> **BGP speaker** BGP发言者
>
> **bidirectional data transfer** 双向/全双工数据传输
>
> **bootstrap protocol(BOOTP)** 引导程序协议
>
> **border gateway protocol(BGP)** 边界网关协议
>
> **botnet** 僵尸网络
>
> **bottleneck link** 瓶颈链路
>
> **bring home** 客邀
>
> **broadcast** 广播
>
> **cable internet access** 电缆因特网接入
>
> **cable modern** 电缆调制解调器
>
> **cable modern termination system(CMTS)** 电缆调制解调器端接系统
>
> **canonical hostname** 规范主机名
>
> **centralized routing algorithm** 集中式路由选择算法
>
> **choke packet** 抑制分组
>
> **circuit** 电路
>
> **circuit switching** 电路交换
>
> **classful addressing** 分类编制
>
> **classless interdomain routing(CIDR)** 无类别域间路由选择
>
> **client** 客户端
>
> **cluster selection strategy** 集群选择策略
>
> **communication link** 通信链路
>
> **congestion avoidance** 拥塞避免
>
> **congestion control** 拥塞控制
>
> **congestion window reduced(CWR)**  拥塞窗口减少
>
> **congestion window(cwnd)** 拥塞窗口
>
> **connection oriented** 面向连接的
>
> **content distribution network(CDN)** 内容分发网络
>
> **content provider network** 内容提供商网络
>
> **control plane** 控制平面
>
> **convergence** 收敛
>
> **count to infinity** 无穷计数
>
> **countdown timer** 倒数计时器
>
> **cumulative acknowledgement** 累积确认
>
> **customer** 客户
>
> **data center** 数据中心
>
> **data center TCP(DCTCP)** 数据中心TCP
>
> **data plane** 数据平面
>
> **datagram** 数据报
>
> **datagram congestion control protocol(DCCP)** 数据报拥塞控制协议
>
> **decentralized routing algorithm** 分布式路由选择算法
>
> **deep packet inspection(DPI)** 深度分组检测
>
> **default gateway** 默认网关
>
> **delay,throughput,reliability(DTR)** 延迟、吞吐量、可靠性
>
> **denial of service(DOS)** 拒绝服务
>
> **demultiplexing** 多路分解
>
> **destination options** 目的选项
>
> **destination port number field** 目的端口号字段
>
> **DHCP decline message** DHCP拒绝报文
>
> **DHCP discover message** DHCP发现报文
>
> **DHCP Inform message** DHCP信息报文
>
> **DHCP offer message** DHCP提供报文
>
> **DHCP release message** DHCP释放报文
>
> **DHCP request message** DHCP请求报文
>
> **digital subscriber line(DSL)** 数字用户线
>
> **distance vector(DV)** 距离向量
>
> **distributed application** 分布式应用程序
>
> **distribution time** 分发时间
>
> **DNS caching** DNS缓存
>
> **don't fragment(DF)** 禁止分片
>
> **domain name system(DNS)** 域名系统
>
> **dotted-decimal notation** 点分十进制表示法
>
> **drop tail** 弃尾
>
> **duplicate data packet** 冗余数据分组
>
> **dynamic adaptive streaming over HTTP(DASH)** 经HTTP的动态适应流
>
> **dynamic host configuration protocol(DHCP)** 动态主机配置协议
>
> **dynamic routing algorithm** 动态路由选择算法
>
> **ECN Echo(ECE)** 显式拥塞提醒回应
>
> **edge router** 边缘路由器
>
> **encapsulating security payload** 封装安全有效载荷
>
> **encapsulation** 封装
>
> **end system** 端系统
>
> **end-end principle** 端到端原则
>
> **end-to-end connection** 端到端连接
>
> **enter deep** 深入
>
> **elastic application** 弹性应用
>
> **event based programming** 基于事件的编程
>
> **explicit congestion notification(ECN)** 显式拥塞通知
>
> **extend simple mail transfer protocol(ESMTP)** 扩展简单邮件传输协议
>
> **external BGP(EBGP)** 外部BGP
>
> **exponential weighted moving average(EWMA)** 指数加权移动平均
>
> **fast recovery** 快速恢复
>
> **fast retransmit** 快速重传
>
> **flooding** 泛洪
>
> **flow control service** 流量控制协议
>
> **flow table** 流表
>
> **fiber to the home(FTTH)** 光纤到户
>
> **file transfer protocol(FTP)** 文件传输协议
>
> **finite state machine(FSM)** 有限状态机
>
> **first come first service(FCFS)** 先来先服务
>
> **first input first output(FIFO)** 先进先出
>
> **forwarding** 转发
>
> **forwarding table** 转发表
>
> **fragment** 片
>
> **frame** 帧
>
> **frequency-division multiplexing(FDM)** 频分复用
>
> **full duplex service** 全双工服务
>
> **gateway router** 网关路由器
>
> **geographically closest** 地理上最近
>
> **geostationary satellite** 同步卫星
>
> **go-back-n(GBN)** 回退N步
>
> **guided media** 导引型媒体
>
> **head of the line(HOL)** 线路前部
>
> **header line** 首部行
>
> **hop by hop options** 逐跳选项
>
> **host** 主机
>
> **host aliasing** 主机别名
>
> **hostname** 主机名
>
> **hot potato routing** 热土豆路由选择
>
> **hybrid fiber coax(HFC)** 混合光纤同轴
>
> **hyper text transfer protocol(HTTP)** 超文本传输协议
>
> **ingress port** 输入端口
>
> **initial sequence number(ISN)** 初始序号
>
> **input port** 输入端口
>
> **instantaneous throughput** 瞬时吞吐量
>
> **inter-autonomous system routing protocol** 自治系统间路由选择协议
>
> **intermediate system to intermediate system(IS-IS)** 中间系统到中间系统
>
> **internal BGP(IBGP)** 内部BGP
>
> **internal router** 内部路由器
>
> **internet control message protocol(ICMP)** 因特网控制报文协议
>
> **internet corporation for assigned names and numbers(ICANN)** 因特网名称与数字地址分配机构
>
> **internet exchange point(IXP)** 因特网交换点
>
> **internet engineering task force(IETF)** 因特网工程任务组
>
> **internet group management protocol(IGMP)** 因特网组管理协议
>
> **internet mail access protocol(IMAP)** 因特网邮件访问协议
>
> **internet protocol(IP) **网际协议
>
> **internet protocol security(IPsec)** 因特网安全协议
>
> **internet service provider(ISP)**  因特网服务提供商
>
> **internet standard** 因特网标准
>
> **intra-autonomous system routing protocol** 自治系统内部路由选择协议
>
> **IP spoofing** IP哄骗
>
> **layer** 分层
>
> **least cost path** 最低成本路径
>
> **link layer switch** 链路层交换机
>
> **link state(LS)** 链路状态
>
> **link state advertisement(LSA)** 链路状态通告
>
> **load distribution** 负载分配
>
> **load insensitive algorithm** 负载迟钝算法
>
> **load sensitive algorithm** 负载敏感算法
>
> **local preference(LOCAL_PREF)** 本地优先级
>
> **logic communication** 逻辑通信
>
> **long term evolution(LTE)** 长期演进
>
> **longest prefix matching rule** 最长前缀匹配规则
>
> **loss tolerant application** 容忍丢失的应用
>
> **low earth orbiting(LEO)** 近地轨道
>
> **mail server aliasing** 邮件服务别名
>
> **managed device** 被管设备
>
> **managed object** 被管对象
>
> **management information base(MIB)** 管理信息库
>
> **managing server** 管理服务器
>
> **manifest file** 告示文件
>
> **malware** 恶意软件
>
> **maximum segment size(MSS)** 最大报文段长度
>
> **maximum transmission unit(MTU)** 最大传输单元
>
> **message** 报文
>
> **more fragment(MF)** 还有分片
>
> **multicast OSPF(MOSPF)** 多播OSPF
>
> **multi-exit discriminator(MED/MULTI_EXIT_DISC)** 多出口鉴别器
>
> **multi-home** 多宿
>
> **multi-homed access ISP** 多宿接入ISP
>
> **must be zero(MBZ)** 必须为零
>
> **NAT translation table** NAT转换表
>
> **media access control(MAC)** 媒体访问控制
>
> **negative acknowledgment(NAK)** 否定确认
>
> **net file system(NFS)** 网络文件系统
>
> **network address translation(NAT)** 网络地址转换
>
> **network architecture** 网络体系结构
>
> **network control server(NCS)** 网络控制服务器
>
> **network functions virtualization(NFV)** 网络功能虚拟化
>
> **network information base(NIB)** 网络信息数据库
>
> **network interface card(NIC)** 网络接口卡
>
> **network management agent** 网络管理代理
>
> **network management protocol** 网络管理协议
>
> **network operations center(NOC)** 网络运营中心
>
> **network service model** 网络服务模型
>
> **nodal processing delay** 节点处理时延
>
> **nonce sum(NS)** 随机数和
>
> **non-persistent connection** 非持续连接
>
> **non-preemptive priority queueing** 非抢占式优先级排队
>
> **offered load** 供给载荷
>
> **open network operating system(ONOS)** 开放网络操作系统
>
> **open shortest path first(OSPF)** 开放式最短路径优先
>
> **open system interconnection reference model(OSI model)** 开放式系统互联网通信参考模型
>
> **OpenFlow agent(OFA)** OpenFlow代理
>
> **OpenFlow controller(OFC)** OpenFlow控制器
>
> **optical Carrier(OC)** 光载波
>
> **optical line terminator(OLT)** 光纤线路端连接器
>
> **optical network terminator(ONT)** 光纤网络端接器
>
> **optional non-transitive** 可选非传递
>
> **optional transitive** 可选传递
>
> **output buffer** 输出缓存
>
> **output port** 输出端口
>
> **output queue** 输出队列
>
> **packet** 分组
>
> **packet loss** 分组丢包
>
> **packet sniffer** 分组嗅探器
>
> **packet switch** 分组交换机
>
> **packet switching** 分组交换
>
> **passive optical network(PON)** 被动光纤网络
>
> **path** 路径
>
> **payload field** 有效载荷字段
>
> **peer** 对等
>
> **peer to peer(P2P)** 点对点
>
> **persistent connection** 持续连接
>
> **per-router control** 每路由器控制
>
> **plug and play protocol** 即插即用协议
>
> **piggyback** 捎带  
>
> **pipelining** 流水线
>
> **point of presence(POP)** 存在点
>
> **point to point** 点对点
>
> **point to point protocol(PPP)** 点对点协议
>
> **poisoned reverse** 毒性逆转
>
> **post office protocol-version 3(POP3)** 第三版邮局
>
> **precedence** 优先级
>
> **prefix** 前缀
>
> **priority queueing** 优先级排队
>
> **propagation delay** 传播时延
>
> **protocol** 协议
>
> **protocol data unit(PDU)** 协议数据单元
>
> **provider** 提供商
>
> **physical medium** 物理媒体
>
> **pull protocol** 拉协议
>
> **push protocol** 推协议
>
> **queuing delay** 排队时延
>
> **quick UDP internet connection(QUIC)** 快速UDP互联网连接
>
> **random early detection(RED)** 随机早期检测
>
> **rarest first** 最稀缺优先
>
> **real time measurement** 实时测量
>
> **reliable data transfer(RDT)** 可靠数据传输
>
> **representational state transfer(REST)** 表征状态传递
>
> **request for comment(RFC)** 请求评论
>
> **request line** 请求行
>
> **resource record(RR)** 资源记录
>
> **retransmission time out(RTO)** 重传超时时间
>
> **round robin(RR) queueing** 循环排队
>
> **round trip time(RTT)** 往返时间
>
> **route** 路径
>
> **route aggregation** 路由聚合
>
> **route summarization** 路由摘要
>
> **router** 路由器
>
> **routing** 路由选择
>
> **routing loop** 路由选择环路
>
> **routing table** 路由选择表
>
> **routing processor** 路由选择处理器
>
> **secure shell(SSH)** 安全外壳
>
> **segment** 报文段
>
> **selective acknowledgement(SACK)** 选择性确认
>
> **selective repeat(SR)** 选择重传
>
> **self clocking** 自计时的
>
> **sequence number** 序号
>
> **server** 服务器
>
> **service abstraction layer(SAL)** 服务抽象层
>
> **shared medium** 共享媒体
>
> **shortest path** 最短路径
>
> **silent period** 静默期
>
> **simple mail transfer protocol(SMTP)** 简单邮件传输协议
>
> **simple network management protocol(SNMP)** 简单网络管理协议
>
> **sliding-window protocol** 滑动窗口协议
>
> **slow start** 慢启动
>
> **slow start threshold(ssthresh)** 慢启动阈值
>
> **socket** 套接字
>
> **software defined network(SDN)** 软件定义网络
>
> **source port number field** 源端口号字段
>
> **source quench** 源抑制
>
> **source sockets layer** 安全套接字层
>
> **splitter** 分配器
>
> **stateless protocol** 无状态协议
>
> **static routing algorithm** 静态路由选择算法
>
> **stop and wait** 停等
>
> **store and forward transmission** 存储转发传输
>
> **stream control transmission protocol(SCTP)** 流控制传输协议
>
> **structure of management information(SMI)** 管理信息结构
>
> **stub network** 存根网络
>
> **subnet mask** 子网掩码
>
> **switching fabirc** 交换结构
>
> **TCP friendly rate control(TFRC)** TCP友好速度控制
>
> **TCP splitting** TCP分岔
>
> **ternary content addressable memory(TCAM)** 三态内容寻址存储器
>
> **three way handshake** 三次握手
>
> **time division multiplexing(TDM)**  时分复用
>
> **time to live(TTL)** 生存时间
>
> **tit for tat** 一报还一报
>
> **top down approach** 自顶向下方方法
>
> **top level domain(TLD)** 顶级域
>
> **torrent** 洪流
>
> **total nodal delay** 节点总时延
>
> **tracker** 追踪器
>
> **traffic intensity** 流量强度
>
> **traffic volume** 通信容量
>
> **transmission control protocol(TCP)** 传输控制协议
>
> **transmission delay** 传输时延
>
> **transmission rate** 传输速度
>
> **trap message** 陷阱报文
>
> **tunnel** 隧道
>
> **tunneling** 建立隧道
>
> **type of service(TOP)** 服务类型
>
> **unchoked** 疏通
>
> **unguided media** 非导引型媒体
>
> **unidirectional data transfer** 单向/半双工数据传输
>
> **unreliable service** 不可靠服务
>
> **unshielded twisted pair(UTP)** 无屏蔽双绞线
>
> **user agent** 用户代理
>
> **user datagram protocol(UDP)** 用户数据报协议
>
> **utilization** 利用率
>
> **weighted fair queueing(WFQ)** 加权公平排队
>
> **well-known discretionary** 公认任意
>
> **well-known mandatory** 公认必遵
>
> **well-known port number** 周知端口号
>
> **work-conserving queuing** 保持工作排队
>
> **zero configuration protocol** 零配置协议

### 附录2 相关RFC

> BGP相关：RFC 4271
>
> BOOTP相关：RFC 951、RFC 1542
>
> cookie相关：RFC 6265
>
> DCCP相关：RFC 4340
>
> DHCP相关：RFC 2131、RFC 2132
>
> DNS相关：RFC 1034、RFC 1035、RFC 2136、RFC 3007
>
> email相关：RFC 5322
>
> HTTP相关：RFC 1945、RFC 2616、RFC 7540
>
> ICMP相关：RFC 792
>
> IMAP相关：RFC 3501
>
> IPv4相关：RFC 791、RFC 950、RFC 2123、RFC 4632
>
> IPv6相关：RFC 1546、RFC 1752、RFC 2460、RFC 4291、RFC 7094
>
> OSPF相关：RFC 1584、RFC 2328
>
> POP3相关：RFC 1939
>
> port相关：RFC 1700、RFC 3232
>
> router相关：RFC 3439
>
> SCTP相关：TFC 3286、RFC 4960
>
> SMTP相关：RFC 821、RFC 1425、RFC 1511、RFC 1521、RFC 1522、RFC 5321 
>
> SNMP相关：RFC 3410、RFC 3416
>
> telnet相关：RFC 854
>
> TFRC相关：RFC 5348
>
> TCP相关：RFC 793、RFC 1122、RFC 1323、RFC 2018、RFC 2581、RFC 3168、RFC 3390、RFC 3649、RFC 3782、RFC 5681
>
> UDP相关：RFC 768